{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guptapawan227/Capstone_AIML/blob/Ashish/Recreated_16thDec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XycWjq1YtXnI"
   },
   "source": [
    "Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_AZpolni4uT",
    "outputId": "cb302f02-8988-4d48-b029-a7018e8350a4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX79JvNILSQK",
    "outputId": "c534e476-dad0-4c90-ce08-b8ea85eba470"
   },
   "outputs": [],
   "source": [
    "!pip3 install ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeHuMI62tbyY"
   },
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01_3Wr6nw-ee",
    "outputId": "10d7a31c-92db-4f92-f57b-c0d43bc5cf25"
   },
   "outputs": [],
   "source": [
    "# Using TensorFlow 1.x only in colab as found a issue with 2.3 version used by colab while working with DNN model fit. Did not observe any issue with Tensor flow 2.1 version on local jupyter enviornment.\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDYfqgy9q1p_",
    "outputId": "8aa69094-8a3c-4f97-eef8-c80a0ebe6126"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, sys, itertools, re \n",
    "from PIL import Image\n",
    "import warnings, pickle, string\n",
    "from dateutil import parser\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Visualization\n",
    "import cufflinks as cf\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "\n",
    "from ftfy import fix_text, badness\n",
    "\n",
    "# Traditional Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sequential Modeling\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, Embedding, LSTM, GRU\n",
    "from keras.layers import BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D\n",
    "from keras.constraints import max_norm, unit_norm\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Tools & Evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import roc_curve, accuracy_score, precision_recall_curve\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjfS1VF6teuM"
   },
   "source": [
    "Reading the data from excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5aLjCsPjai0",
    "outputId": "01562e57-997b-485e-a0eb-6beee2a6f1ee"
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('/content/drive/MyDrive/Capstone/input_data.xlsx')\n",
    "#data=pd.read_excel('input_data.xlsx')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvAO8EEEtmny"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXoojqxIEWGh"
   },
   "source": [
    "## Univariate visualization\n",
    "Single-variable or univariate visualization is the simplest type of visualization which consists of observations on only a single characteristic or attribute. Univariate visualization includes histogram, bar plots and line charts.\n",
    "\n",
    "### The distribution of Assignment groups\n",
    "Plots how the assignments groups are scattered across the dataset. The bar chart, histogram and pie chart tells the frequency of any ticket assigned to any group OR the tickets count for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "h4HmTOOQqTg7",
    "outputId": "4138fafd-3101-4959-a47e-8e1ab2248599"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXfghUHQjo95",
    "outputId": "c215b0c8-47b1-4cdb-ab25-c3aa607771b4"
   },
   "outputs": [],
   "source": [
    "assignment_group_count=data['Assignment group'].value_counts()\n",
    "assignment_group_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Dd91Cg37qrN3",
    "outputId": "9cfa3f3c-c24d-4ea1-bf5a-1150ee4bb36a"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(50,10))\n",
    "ax=sns.countplot(x='Assignment group', data=data)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1aYzasoBsjB",
    "outputId": "ee948611-a68b-46a6-9bbf-544c2225cfd4"
   },
   "outputs": [],
   "source": [
    "assignment_group_count.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFeL_BzlBsjB",
    "outputId": "2c1a5e28-3cb7-4cb2-d6b6-d39b6bf2630e"
   },
   "outputs": [],
   "source": [
    "assignment_group_count.tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eAeh9jCj5xd"
   },
   "source": [
    "### Check Missing Values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LHjYyAk9b1a",
    "outputId": "e032f786-bf7d-4b7a-e09a-2cf4088d8250"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "W9u7hQHExVL1",
    "outputId": "dc055998-bab5-4f22-9b4e-c71cc19a1ad1"
   },
   "outputs": [],
   "source": [
    "data[data[\"Short description\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyohpEPk9icQ"
   },
   "source": [
    "### Copy Short Description to Description if the Description value is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jL2xmtIN9EE3"
   },
   "outputs": [],
   "source": [
    "data.Description.fillna(data[\"Short description\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "ea8mfm119PZZ",
    "outputId": "899ba20e-a4b3-4a0b-ad20-60220082614e"
   },
   "outputs": [],
   "source": [
    "data[data[\"Description\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imMRGWAqeJQB"
   },
   "outputs": [],
   "source": [
    "data['Short description'] = data['Short description'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCyUJGoMz2rT",
    "outputId": "c2e788ef-6452-4bcc-f683-3f63de2d8a9e"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_kHK1RmQEWGl",
    "outputId": "c3cbf520-939f-4c47-d8e6-2a2b0ab140ac"
   },
   "outputs": [],
   "source": [
    "init_notebook_mode()\n",
    "cf.go_offline()\n",
    "\n",
    "# Assignment group distribution\n",
    "print('\\033[1mTotal assignment groups:\\033[0m', data['Assignment group'].nunique())\n",
    "\n",
    "# Histogram\n",
    "data['Assignment group'].iplot(\n",
    "    kind='hist',\n",
    "    xTitle='Assignment Group',\n",
    "    yTitle='count',\n",
    "    title='Assignment Group Distribution- Histogram (Fig-1)')\n",
    "\n",
    "# Pie chart\n",
    "assgn_grp = pd.DataFrame(data.groupby('Assignment group').size(),columns = ['Count']).reset_index()\n",
    "assgn_grp.iplot(\n",
    "    kind='pie', \n",
    "    labels='Assignment group', \n",
    "    values='Count', \n",
    "    title='Assignment Group Distribution- Pie Chart (Fig-2)', \n",
    "    hoverinfo=\"label+percent+name\", hole=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5Bsf1i2EWGp"
   },
   "source": [
    "### Lets visualize the percentage of incidents per assignment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "9tqKaGygEWGp",
    "outputId": "84f196b5-9890-4134-a258-fd8f917f0b35"
   },
   "outputs": [],
   "source": [
    "# Plot to visualize the percentage data distribution across different groups\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,5))\n",
    "ax = sns.countplot(x=\"Assignment group\", data=data, order=data[\"Assignment group\"].value_counts().index)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(format(p.get_height()/len(data.index)*100, '.2f')+\"%\"), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'bottom', rotation=90, xytext = (0, 10), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzt6MERbEWGp"
   },
   "source": [
    "### Top 20 and Bottom 20 assignment groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdWL2G_6EWGq"
   },
   "outputs": [],
   "source": [
    "top_20 = data['Assignment group'].value_counts().nlargest(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "_42WL7ChEWGq",
    "outputId": "97264ffc-471f-4e22-869c-529404cd7e8c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(top_20['index'],top_20['Assignment group'])\n",
    "plt.title('Top 20 Assignment groups with highest number of Tickets')\n",
    "plt.xlabel('Assignment Group')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of Tickets')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + .005, yval)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LK54m2f1EWGq"
   },
   "outputs": [],
   "source": [
    "bottom_20 = data['Assignment group'].value_counts().nsmallest(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "M3NUKDXWEWGq",
    "outputId": "91570300-0bf9-4c75-ac76-d0ad099a4623"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(bottom_20['index'],bottom_20['Assignment group'])\n",
    "plt.title('Bottom 20 Assignment groups with small number of Tickets')\n",
    "plt.xlabel('Assignment Group')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of Tickets')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + .005, yval)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt_wGlGxEWGr"
   },
   "source": [
    "### The distribution of Callers\n",
    "Plots how the callers are associated with tickets and what are the assignment groups they most frequently raise tickets for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "YCyEHmv5EWGr",
    "outputId": "3a5fa032-9f52-48e7-8007-f300416254c4"
   },
   "outputs": [],
   "source": [
    "# Find out top 10 callers in terms of frequency of raising tickets in the entire dataset\n",
    "print('\\033[1mTotal caller count:\\033[0m', data['Caller'].nunique())\n",
    "df = pd.DataFrame(data.groupby(['Caller']).size().nlargest(10), columns=['Count']).reset_index()\n",
    "df.iplot(kind='pie',\n",
    "         labels='Caller', \n",
    "         values='Count', \n",
    "         title='Top 10 caller- Pie Chart (Fig-7)',\n",
    "         colorscale='-spectral',\n",
    "         pull=[0,0,0,0,0.05,0.1,0.15,0.2,0.25,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRlvMWhqEWGs"
   },
   "source": [
    "### Top 5 callers in each assignment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "blKl0U3wEWGs",
    "outputId": "9a488327-e927-4093-bf78-0c4d1edba838"
   },
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "s = data['Caller'].groupby(data['Assignment group']).value_counts()\n",
    "caller_grp = pd.DataFrame(s.groupby(level=0).nlargest(top_n).reset_index(level=0, drop=True))\n",
    "caller_grp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BNsOOO3EWGs"
   },
   "source": [
    "### The distribution of description lengths\n",
    "Plots the variation of length and word count of new description attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yMk1BMBDEWGs",
    "outputId": "43226c44-f85e-4cd0-e573-a197e7850d77"
   },
   "outputs": [],
   "source": [
    "data.insert(1, 'desc_len', data['Description'].astype(str).apply(len))\n",
    "data.insert(5, 'desc_word_count', data['Description'].apply(lambda x: len(str(x).split())))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kypLEsJrEWGt",
    "outputId": "4a8a846a-0433-4aec-8ada-6c4a7f6ba64a"
   },
   "outputs": [],
   "source": [
    "# Description text length\n",
    "data['desc_len'].iplot(\n",
    "    kind='bar',\n",
    "    xTitle='text length',\n",
    "    yTitle='count',\n",
    "    colorscale='-ylgn',\n",
    "    title='Description Text Length Distribution (Fig-11)')\n",
    "\n",
    "# Description word count\n",
    "data['desc_word_count'].iplot(\n",
    "    kind='bar',\n",
    "    xTitle='word count',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    colorscale='-bupu',\n",
    "    title='Description Word Count Distribution (Fig-12)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coPKRzP7BsjE"
   },
   "source": [
    "## Create a rule based engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNgvxqASBsjE"
   },
   "outputs": [],
   "source": [
    "df_rules = pd.read_csv('/content/drive/MyDrive/Capstone/Rule_matrix.csv')\n",
    "#df_rules = pd.read_csv(\"Rule_matrix1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6-JgP7vBsjF"
   },
   "outputs": [],
   "source": [
    "def applyRules(datadf,rulesdf,Description,ShortDescription):\n",
    "    datadf['pred_group'] = np.nan\n",
    "    for i, row in rulesdf.iterrows():                  \n",
    "        for j, row in datadf.iterrows():\n",
    "            if pd.notna(datadf[ShortDescription][j]):\n",
    "                if (('erp' in datadf[ShortDescription][j]) and (('EU_tool' in datadf[ShortDescription][j]))):\n",
    "                        datadf['pred_group'][j] = 'GRP_25'\n",
    "        for j, row in datadf.iterrows():\n",
    "            if pd.notna(datadf[Description][j]):\n",
    "                if (datadf[Description][j] == 'the'):\n",
    "                    datadf['pred_group'][j] = 'GRP_17' \n",
    "                \n",
    "                if (('finance_app' in ((datadf[ShortDescription][j]) or datadf[Description][j])) and ('HostName_1132' not in datadf[ShortDescription][j])):\n",
    "                    datadf['pred_group'][j] = 'GRP_55'\n",
    "                \n",
    "                if (('processor' in datadf[Description][j]) and ('engg' in datadf[Description][j])):\n",
    "                    datadf['pred_group'][j] = 'GRP_58'\n",
    "                \n",
    "                                     \n",
    "        if rulesdf['Short Desc Rule'][i] == 'begins with' and rulesdf['Desc Rule'][i] == 'begins with' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[ShortDescription][j]) and pd.notna(datadf[Description][j]):\n",
    "                    if ((datadf[ShortDescription][j].startswith(rulesdf['Short Dec Keyword'][i])) and (datadf[Description][j].startswith(rulesdf['Dec keyword'][i]))):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "                        \n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'begins with' and pd.notna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]) and pd.notna(datadf['Caller'][j]):\n",
    "                    if ((datadf[Description][j].startswith(rulesdf['Desc Rule'][i]) and (rulesdf['User'][i] == datadf['Caller'][j]))):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "                        \n",
    "        if rulesdf['Short Desc Rule'][i] == 'contains' and pd.notna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if (pd.notna(datadf[ShortDescription][j]) and pd.notna(datadf['Caller'][j])):\n",
    "                     if ((rulesdf['Short Dec Keyword'][i] in datadf[ShortDescription][j]) and (rulesdf['User'][i] == datadf['Caller'][j])):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if rulesdf['Short Desc Rule'][i] == 'contains' and pd.isna(rulesdf['Desc Rule'][i]) and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[ShortDescription][j]):\n",
    "                    if (rulesdf['Short Dec Keyword'][i] in datadf[ShortDescription][j]):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'begins with' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]):\n",
    "                    if (datadf[Description][j].startswith(rulesdf['Dec keyword'][i])):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'contains' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]):\n",
    "                    if (rulesdf['Dec keyword'][i] in datadf[Description][j]):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'not contain' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]):\n",
    "                    if (rulesdf['Dec keyword'][i] in datadf[Description][j]):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "\n",
    "\n",
    "        if rulesdf['Short Desc Rule'][i] == 'not contain' and pd.isna(rulesdf['Desc Rule'][i]) and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "\n",
    "                if pd.notna(datadf[ShortDescription][j]):\n",
    "                    if (rulesdf['Short Dec Keyword'][i] in datadf[ShortDescription][j]):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'not contain' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]):\n",
    "                    if (datadf[Description][j].startswith(rulesdf['Dec keyword'][i])):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "        if pd.isna(rulesdf['Short Desc Rule'][i]) and rulesdf['Desc Rule'][i] == 'contains' and pd.isna(rulesdf['User'][i]):\n",
    "            for j, row in datadf.iterrows():\n",
    "                if pd.notna(datadf[Description][j]):\n",
    "                    if (rulesdf['Dec keyword'][i] in datadf[Description][j]):\n",
    "                        datadf['pred_group'][j] = rulesdf['Group'][i]\n",
    "\n",
    "    return datadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "bb6Q0RQGBsjG",
    "outputId": "3e5b0a29-c741-4bae-8dae-8e76b1ce053c"
   },
   "outputs": [],
   "source": [
    "rules_applied_df = applyRules(data,df_rules,'Description','Short description')\n",
    "rules_applied_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9NJjimoBsjH",
    "outputId": "87622467-a402-47bd-8294-e477498fbace"
   },
   "outputs": [],
   "source": [
    "rules_applied_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlLZAXimBsjH",
    "outputId": "73ea2d69-6602-4027-f65b-ae05bfa419b4"
   },
   "outputs": [],
   "source": [
    "rules_applied_df = rules_applied_df[(rules_applied_df['pred_group'].isna())]\n",
    "rules_applied_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAka7ylMBsjH",
    "outputId": "2b543314-3604-44d3-f785-ce5c135f627c"
   },
   "outputs": [],
   "source": [
    "assignment_group_count=rules_applied_df['Assignment group'].value_counts()\n",
    "assignment_group_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jsmb0Q7u90k2"
   },
   "source": [
    "### Concatenate Short Description and Description Column into New Description, drop the previous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEfP-wfh-0Nb"
   },
   "outputs": [],
   "source": [
    "#Concatenate Short Description and Description columns\n",
    "rules_applied_df['New Description'] = rules_applied_df['Description'] + ' ' +rules_applied_df['Short description']\n",
    "\n",
    "clean_data=rules_applied_df.drop(['Short description', 'Description', 'pred_group', 'desc_len', 'desc_word_count'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVB_Dzw7bz-S",
    "outputId": "a2df2840-74c4-4471-c0f0-5ad973a263ee"
   },
   "outputs": [],
   "source": [
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWWXT5EnBsjI"
   },
   "source": [
    "## Fixing Garbled Text/ Mojibake using ftfy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "G9bghLidBsjJ",
    "outputId": "1ab73c1c-75ea-4ed7-c9f4-e181012ee464"
   },
   "outputs": [],
   "source": [
    "# Write a function to apply to the dataset to detect Mojibakes\n",
    "def is_mojibake_impacted(text):\n",
    "    if not badness.sequence_weirdness(text):\n",
    "        # nothing weird, should be okay\n",
    "        return True\n",
    "    try:\n",
    "        text.encode('sloppy-windows-1252')\n",
    "    except UnicodeEncodeError:\n",
    "        # Not CP-1252 encodable, probably fine\n",
    "        return True\n",
    "    else:\n",
    "        # Encodable as CP-1252, Mojibake alert level high\n",
    "        return False\n",
    "# Check the dataset for mojibake impact\n",
    "clean_data[~clean_data.iloc[:,:].applymap(is_mojibake_impacted).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEYRzxjDBsjJ",
    "outputId": "f8565868-3a52-4956-adc7-59ae755298bc"
   },
   "outputs": [],
   "source": [
    "# Take an example of row# 8471 Short Desc and fix it\n",
    "print('Grabled text: \\033[1m%s\\033[0m\\nFixed text: \\033[1m%s\\033[0m' % (clean_data['New Description'][8471], \n",
    "                                                                        fix_text(clean_data['New Description'][8471])))\n",
    "\n",
    "# List all mojibakes defined in ftfy library\n",
    "print('\\nMojibake Symbol RegEx:\\n', badness.MOJIBAKE_SYMBOL_RE.pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxVgsJGRBsjJ",
    "outputId": "c6f64f23-41fe-445e-f3c4-0ffdda56a07e"
   },
   "outputs": [],
   "source": [
    "# Sanitize the dataset from Mojibakes\n",
    "clean_data['New Description'] = clean_data['New Description'].apply(fix_text)\n",
    "\n",
    "# Visualize that row# 8471\n",
    "clean_data.loc[8471]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4INDyU8-_RoR"
   },
   "source": [
    "## Cleaning & Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXY-QspE_9e5"
   },
   "outputs": [],
   "source": [
    "def date_validity(date_str):\n",
    "    try:\n",
    "        parser.parse(date_str)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zOXTxcwZ3b2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process(text_string):\n",
    "    text=text_string.lower()\n",
    "    text_string = ' '.join([w for w in text_string.split() if not date_validity(w)])\n",
    "    text_string = re.sub(r\"received from:\",'',text_string)\n",
    "    text_string = re.sub(r\"from:\",' ',text_string)\n",
    "    text_string = re.sub(r\"to:\",' ',text_string)\n",
    "    text_string = re.sub(r\"subject:\",' ',text_string)\n",
    "    text_string = re.sub(r\"sent:\",' ',text_string)\n",
    "    text_string = re.sub(r\"ic:\",' ',text_string)\n",
    "    text_string = re.sub(r\"cc:\",' ',text_string)\n",
    "    text_string = re.sub(r\"bcc:\",' ',text_string)\n",
    "    text_string = re.sub(r'\\S*@\\S*\\s?', '', text_string)\n",
    "    text_string = re.sub(r'\\d+','' ,text_string)\n",
    "    text_string = re.sub(r'\\n',' ',text_string)\n",
    "    text_string = re.sub(r'#','', text_string)\n",
    "    text_string = re.sub(r'&;?', 'and',text_string)\n",
    "    text_string = re.sub(r'\\&\\w*;', '', text_string)\n",
    "    text_string = re.sub(r'https?:\\/\\/.*\\/\\w*', '', text_string)  \n",
    "    #text_string= ''.join(c for c in text_string if c <= '\\uFFFF') \n",
    "    text_string = text_string.strip()\n",
    "    #text_string = ' '.join(re.sub(\"[^\\u0030-\\u0039\\u0041-\\u005a\\u0061-\\u007a]\", \" \", text_string).split())\n",
    "    text_string = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text_string)\n",
    "    text_string = re.sub(' +', ' ', text_string)\n",
    "    text_string = text_string.replace(r'\\b\\w\\b','').replace(r'\\s+', ' ')\n",
    "    text_string = text_string.strip()\n",
    "    return text_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UBm9uIvPr8f"
   },
   "outputs": [],
   "source": [
    "clean_data[\"Clean_Description\"] = clean_data[\"New Description\"].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "5CsFdd6BS1pw",
    "outputId": "4a414b56-97cd-4332-cc5c-fe5499804b47"
   },
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBwzB1oFYRiQ"
   },
   "source": [
    "## Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n795kT7hYjSo"
   },
   "source": [
    "#### Load the consolidated final translated pickle file which contains the language translations. The Process used for language translation is commented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9yVx3oMXVWG5"
   },
   "outputs": [],
   "source": [
    "#with open('/content/drive/MyDrive/Capstone/Final_Translated_combined.pkl','rb') as f:\n",
    "with open('Final_Translated_combined.pkl','rb') as f:\n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKfqoJo1Vu4K",
    "outputId": "43eb4033-6370-452c-99c8-70bba4e4d156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8466 entries, 0 to 48\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Caller             8466 non-null   object\n",
      " 1   Assignment group   8466 non-null   object\n",
      " 2   New Description    8466 non-null   object\n",
      " 3   Clean_Description  8466 non-null   object\n",
      " 4   language           8466 non-null   object\n",
      " 5   Translated Text    8466 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 463.0+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "RNYuIWcuhqrR",
    "outputId": "1b14ae46-8ab5-4209-d055-7c894737362e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>New Description</th>\n",
       "      <th>Clean_Description</th>\n",
       "      <th>language</th>\n",
       "      <th>Translated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>wgmqlnzh vpebwoat</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>早上开机后显示器不出图像。 显示器不亮</td>\n",
       "      <td>早上开机后显示器不出图像。 显示器不亮</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The display does not appear in the morning. Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rtjwbuev gfpwdetq</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>prtSID_737--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打...</td>\n",
       "      <td>prtSID_--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打印机错误。</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The prtsid _- file cannot be printed to the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fupikdoa gjkytoeh</td>\n",
       "      <td>GRP_48</td>\n",
       "      <td>客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开</td>\n",
       "      <td>客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The online delivery unit provided by the custo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>kyagjxdh dmtjpbnz</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>进行采购时显示\"找不到员工1111154833的数据,请通知系统管理员\" erp无法进行采购...</td>\n",
       "      <td>进行采购时显示\"找不到员工的数据,请通知系统管理员\" erp无法进行采购(转给贺正平)</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Show \"Data from the employee, please notify th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xqyjztnm onfusvlz</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>to 小贺,早上电脑开机开不出来 电脑开机开不出来</td>\n",
       "      <td>to 小贺,早上电脑开机开不出来 电脑开机开不出来</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>To small congratulations, the computer does no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Caller Assignment group  \\\n",
       "44  wgmqlnzh vpebwoat           GRP_30   \n",
       "45  rtjwbuev gfpwdetq           GRP_31   \n",
       "46  fupikdoa gjkytoeh           GRP_48   \n",
       "47  kyagjxdh dmtjpbnz           GRP_30   \n",
       "48  xqyjztnm onfusvlz           GRP_30   \n",
       "\n",
       "                                      New Description  \\\n",
       "44                                早上开机后显示器不出图像。 显示器不亮   \n",
       "45  prtSID_737--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打...   \n",
       "46               客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开   \n",
       "47  进行采购时显示\"找不到员工1111154833的数据,请通知系统管理员\" erp无法进行采购...   \n",
       "48                          to 小贺,早上电脑开机开不出来 电脑开机开不出来   \n",
       "\n",
       "                                   Clean_Description language  \\\n",
       "44                               早上开机后显示器不出图像。 显示器不亮    zh-cn   \n",
       "45  prtSID_--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打印机错误。    zh-cn   \n",
       "46              客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开    zh-cn   \n",
       "47       进行采购时显示\"找不到员工的数据,请通知系统管理员\" erp无法进行采购(转给贺正平)    zh-cn   \n",
       "48                         to 小贺,早上电脑开机开不出来 电脑开机开不出来    zh-cn   \n",
       "\n",
       "                                      Translated Text  \n",
       "44  The display does not appear in the morning. Di...  \n",
       "45  The prtsid _- file cannot be printed to the pr...  \n",
       "46  The online delivery unit provided by the custo...  \n",
       "47  Show \"Data from the employee, please notify th...  \n",
       "48  To small congratulations, the computer does no...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpDjY6fmrFaW",
    "outputId": "416ee6e2-27d3-4ad0-c4b0-2551dbb53da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      43.000000\n",
       "mean      196.883721\n",
       "std       596.778064\n",
       "min        16.000000\n",
       "25%        31.000000\n",
       "50%        68.000000\n",
       "75%       145.500000\n",
       "max      3941.000000\n",
       "Name: Assignment group, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_group_cnt=clean_data['Assignment group'].value_counts()\n",
    "assignment_group_cnt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTZyoprphuPp"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_qdWy1yBsjO",
    "outputId": "afe2857e-05b2-444d-a88e-4ca5e92087d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com/simple, https://urm.nvidia.com/artifactory/api/pypi/sw-colossus-pypi/simple\n",
      "Requirement already satisfied: nltk in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from nltk) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aroy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aroy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gt5RRxDkBsjO"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "def find_synonyms(word):\n",
    "  synonyms = []\n",
    "  for synset in wordnet.synsets(word):\n",
    "    for syn in synset.lemma_names():\n",
    "      synonyms.append(syn)\n",
    "\n",
    "  # using this to drop duplicates while maintaining word order (closest synonyms comes first)\n",
    "  synonyms_without_duplicates = list(OrderedDict.fromkeys(synonyms))\n",
    "  return synonyms_without_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wkwvCo2YBsjP"
   },
   "outputs": [],
   "source": [
    "def create_set_of_new_sentences(sentence, max_syn_per_word = 3):\n",
    "  count = 0\n",
    "  new_sentences = []\n",
    "  for word in word_tokenize(sentence):\n",
    "    if len(word)<=3 : continue \n",
    "    for synonym in find_synonyms(word)[0:max_syn_per_word]:\n",
    "      synonym = synonym.replace('_', ' ') #restore space character\n",
    "      new_sentence = sentence.replace(word,synonym)\n",
    "      if count <= 4:\n",
    "        new_sentences.append(new_sentence)\n",
    "        count += 1    \n",
    "  return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Erip7CBw7P_P",
    "outputId": "bba106e5-3d55-4a2b-b460-fa1636d9abb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>New Description</th>\n",
       "      <th>Clean_Description</th>\n",
       "      <th>language</th>\n",
       "      <th>Translated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jyoqwxhz clhxsoqy</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>event: critical:HostName_221.company.com the v...</td>\n",
       "      <td>event: critical:HostName_.company.com the valu...</td>\n",
       "      <td>en</td>\n",
       "      <td>event: critical:HostName_.company.com the valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sigfdwcj reofwzlm</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>when undocking pc , screen will not come back ...</td>\n",
       "      <td>when undocking pc , screen will not come back ...</td>\n",
       "      <td>en</td>\n",
       "      <td>When undocking pc , screen want distress come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kxsceyzo naokumlb</td>\n",
       "      <td>GRP_4</td>\n",
       "      <td>\\n\\nreceived from: kxsceyzo.naokumlb@gmail.com...</td>\n",
       "      <td>gentles, have two devices that are trying to s...</td>\n",
       "      <td>en</td>\n",
       "      <td>gentles, have two devices did are trying to sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yisohglr uvteflgb</td>\n",
       "      <td>GRP_5</td>\n",
       "      <td>\\n\\nreceived from: yisohglr.uvteflgb@gmail.com...</td>\n",
       "      <td>hi - the printer printer is not working and ne...</td>\n",
       "      <td>en</td>\n",
       "      <td>Hi - the printer printer is distress working a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bpctwhsn kzqsbmtp</td>\n",
       "      <td>GRP_6</td>\n",
       "      <td>received from: monitoring_tool@company.com\\n\\n...</td>\n",
       "      <td>job Job_ failed in job_scheduler at: job Job_ ...</td>\n",
       "      <td>en</td>\n",
       "      <td>job Job_ failed in job_scheduler at: job Job_ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Caller Assignment group  \\\n",
       "6   jyoqwxhz clhxsoqy            GRP_1   \n",
       "17  sigfdwcj reofwzlm            GRP_3   \n",
       "32  kxsceyzo naokumlb            GRP_4   \n",
       "43  yisohglr uvteflgb            GRP_5   \n",
       "47  bpctwhsn kzqsbmtp            GRP_6   \n",
       "\n",
       "                                      New Description  \\\n",
       "6   event: critical:HostName_221.company.com the v...   \n",
       "17  when undocking pc , screen will not come back ...   \n",
       "32  \\n\\nreceived from: kxsceyzo.naokumlb@gmail.com...   \n",
       "43  \\n\\nreceived from: yisohglr.uvteflgb@gmail.com...   \n",
       "47  received from: monitoring_tool@company.com\\n\\n...   \n",
       "\n",
       "                                    Clean_Description language  \\\n",
       "6   event: critical:HostName_.company.com the valu...       en   \n",
       "17  when undocking pc , screen will not come back ...       en   \n",
       "32  gentles, have two devices that are trying to s...       en   \n",
       "43  hi - the printer printer is not working and ne...       en   \n",
       "47  job Job_ failed in job_scheduler at: job Job_ ...       en   \n",
       "\n",
       "                                      Translated Text  \n",
       "6   event: critical:HostName_.company.com the valu...  \n",
       "17  When undocking pc , screen want distress come ...  \n",
       "32  gentles, have two devices did are trying to sh...  \n",
       "43  Hi - the printer printer is distress working a...  \n",
       "47  job Job_ failed in job_scheduler at: job Job_ ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe with records not in GRP_0\n",
    "new_dataframe = clean_data[clean_data[\"Assignment group\"] != 'GRP_0']\n",
    "zero_dataframe = clean_data[clean_data[\"Assignment group\"] == 'GRP_0']\n",
    "new_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB8ELEaPRyuQ",
    "outputId": "b5967120-c74d-4f55-b6db-4c32c528e756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4525, 6), (8466, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe.shape, clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "yUnTAlH_SXEW",
    "outputId": "befe45e6-6c61-4f8b-ee99-cb01c29c1509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>New Description</th>\n",
       "      <th>Clean_Description</th>\n",
       "      <th>language</th>\n",
       "      <th>Translated Text</th>\n",
       "      <th>Augmented_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jyoqwxhz clhxsoqy</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>event: critical:HostName_221.company.com the v...</td>\n",
       "      <td>event: critical:HostName_.company.com the valu...</td>\n",
       "      <td>en</td>\n",
       "      <td>event: critical:HostName_.company.com the valu...</td>\n",
       "      <td>[event: critical:HostName_.company.com the val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sigfdwcj reofwzlm</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>when undocking pc , screen will not come back ...</td>\n",
       "      <td>when undocking pc , screen will not come back ...</td>\n",
       "      <td>en</td>\n",
       "      <td>When undocking pc , screen want distress come ...</td>\n",
       "      <td>[When undock pc , screen want distress come ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kxsceyzo naokumlb</td>\n",
       "      <td>GRP_4</td>\n",
       "      <td>\\n\\nreceived from: kxsceyzo.naokumlb@gmail.com...</td>\n",
       "      <td>gentles, have two devices that are trying to s...</td>\n",
       "      <td>en</td>\n",
       "      <td>gentles, have two devices did are trying to sh...</td>\n",
       "      <td>[pacify, have two devices did are trying to sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yisohglr uvteflgb</td>\n",
       "      <td>GRP_5</td>\n",
       "      <td>\\n\\nreceived from: yisohglr.uvteflgb@gmail.com...</td>\n",
       "      <td>hi - the printer printer is not working and ne...</td>\n",
       "      <td>en</td>\n",
       "      <td>Hi - the printer printer is distress working a...</td>\n",
       "      <td>[Hi - the printer printer is distress working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bpctwhsn kzqsbmtp</td>\n",
       "      <td>GRP_6</td>\n",
       "      <td>received from: monitoring_tool@company.com\\n\\n...</td>\n",
       "      <td>job Job_ failed in job_scheduler at: job Job_ ...</td>\n",
       "      <td>en</td>\n",
       "      <td>job Job_ failed in job_scheduler at: job Job_ ...</td>\n",
       "      <td>[job Job_ fail in job_scheduler at: job Job_ f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>wgmqlnzh vpebwoat</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>早上开机后显示器不出图像。 显示器不亮</td>\n",
       "      <td>早上开机后显示器不出图像。 显示器不亮</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The display does not appear in the morning. Di...</td>\n",
       "      <td>[The display does not appear in the morning. D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rtjwbuev gfpwdetq</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>prtSID_737--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打...</td>\n",
       "      <td>prtSID_--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打印机错误。</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The prtsid _- file cannot be printed to the pr...</td>\n",
       "      <td>[The prtsid _- file cannot be printed to the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fupikdoa gjkytoeh</td>\n",
       "      <td>GRP_48</td>\n",
       "      <td>客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开</td>\n",
       "      <td>客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>The online delivery unit provided by the custo...</td>\n",
       "      <td>[The on-line delivery unit provided by the cus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>kyagjxdh dmtjpbnz</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>进行采购时显示\"找不到员工1111154833的数据,请通知系统管理员\" erp无法进行采购...</td>\n",
       "      <td>进行采购时显示\"找不到员工的数据,请通知系统管理员\" erp无法进行采购(转给贺正平)</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Show \"Data from the employee, please notify th...</td>\n",
       "      <td>[show \"Data from the employee, please notify t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xqyjztnm onfusvlz</td>\n",
       "      <td>GRP_30</td>\n",
       "      <td>to 小贺,早上电脑开机开不出来 电脑开机开不出来</td>\n",
       "      <td>to 小贺,早上电脑开机开不出来 电脑开机开不出来</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>To small congratulations, the computer does no...</td>\n",
       "      <td>[To small congratulations, the computer does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Caller Assignment group  \\\n",
       "6   jyoqwxhz clhxsoqy            GRP_1   \n",
       "17  sigfdwcj reofwzlm            GRP_3   \n",
       "32  kxsceyzo naokumlb            GRP_4   \n",
       "43  yisohglr uvteflgb            GRP_5   \n",
       "47  bpctwhsn kzqsbmtp            GRP_6   \n",
       "..                ...              ...   \n",
       "44  wgmqlnzh vpebwoat           GRP_30   \n",
       "45  rtjwbuev gfpwdetq           GRP_31   \n",
       "46  fupikdoa gjkytoeh           GRP_48   \n",
       "47  kyagjxdh dmtjpbnz           GRP_30   \n",
       "48  xqyjztnm onfusvlz           GRP_30   \n",
       "\n",
       "                                      New Description  \\\n",
       "6   event: critical:HostName_221.company.com the v...   \n",
       "17  when undocking pc , screen will not come back ...   \n",
       "32  \\n\\nreceived from: kxsceyzo.naokumlb@gmail.com...   \n",
       "43  \\n\\nreceived from: yisohglr.uvteflgb@gmail.com...   \n",
       "47  received from: monitoring_tool@company.com\\n\\n...   \n",
       "..                                                ...   \n",
       "44                                早上开机后显示器不出图像。 显示器不亮   \n",
       "45  prtSID_737--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打...   \n",
       "46               客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开   \n",
       "47  进行采购时显示\"找不到员工1111154833的数据,请通知系统管理员\" erp无法进行采购...   \n",
       "48                          to 小贺,早上电脑开机开不出来 电脑开机开不出来   \n",
       "\n",
       "                                    Clean_Description language  \\\n",
       "6   event: critical:HostName_.company.com the valu...       en   \n",
       "17  when undocking pc , screen will not come back ...       en   \n",
       "32  gentles, have two devices that are trying to s...       en   \n",
       "43  hi - the printer printer is not working and ne...       en   \n",
       "47  job Job_ failed in job_scheduler at: job Job_ ...       en   \n",
       "..                                                ...      ...   \n",
       "44                                早上开机后显示器不出图像。 显示器不亮    zh-cn   \n",
       "45   prtSID_--文件无法打印到打印机,提示打印机错误。 文件无法打印到打印机,提示打印机错误。    zh-cn   \n",
       "46               客户提供的在线送货单生成系统打不开,需尽快解决 客户提供的在线系统打不开    zh-cn   \n",
       "47        进行采购时显示\"找不到员工的数据,请通知系统管理员\" erp无法进行采购(转给贺正平)    zh-cn   \n",
       "48                          to 小贺,早上电脑开机开不出来 电脑开机开不出来    zh-cn   \n",
       "\n",
       "                                      Translated Text  \\\n",
       "6   event: critical:HostName_.company.com the valu...   \n",
       "17  When undocking pc , screen want distress come ...   \n",
       "32  gentles, have two devices did are trying to sh...   \n",
       "43  Hi - the printer printer is distress working a...   \n",
       "47  job Job_ failed in job_scheduler at: job Job_ ...   \n",
       "..                                                ...   \n",
       "44  The display does not appear in the morning. Di...   \n",
       "45  The prtsid _- file cannot be printed to the pr...   \n",
       "46  The online delivery unit provided by the custo...   \n",
       "47  Show \"Data from the employee, please notify th...   \n",
       "48  To small congratulations, the computer does no...   \n",
       "\n",
       "                                       Augmented_data  \n",
       "6   [event: critical:HostName_.company.com the val...  \n",
       "17  [When undock pc , screen want distress come ba...  \n",
       "32  [pacify, have two devices did are trying to sh...  \n",
       "43  [Hi - the printer printer is distress working ...  \n",
       "47  [job Job_ fail in job_scheduler at: job Job_ f...  \n",
       "..                                                ...  \n",
       "44  [The display does not appear in the morning. D...  \n",
       "45  [The prtsid _- file cannot be printed to the p...  \n",
       "46  [The on-line delivery unit provided by the cus...  \n",
       "47  [show \"Data from the employee, please notify t...  \n",
       "48  [To small congratulations, the computer does n...  \n",
       "\n",
       "[4525 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsyn=1\n",
    "new_dataframe[\"Augmented_data\"] = new_dataframe.apply(lambda x: create_set_of_new_sentences(x['Translated Text'], maxsyn),axis=1)\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ThnwxmfATCun",
    "outputId": "2c2a1108-513c-4416-abf1-31ecbf28683f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroy\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happen again The PC has been releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has be releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>ufawcgob aowhxjky</td>\n",
       "      <td>GRP_62</td>\n",
       "      <td>en</td>\n",
       "      <td>i at the unable to access the machine utilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>ufawcgob aowhxjky</td>\n",
       "      <td>GRP_62</td>\n",
       "      <td>en</td>\n",
       "      <td>i at the unable to entree the machine utilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>ufawcgob aowhxjky</td>\n",
       "      <td>GRP_62</td>\n",
       "      <td>en</td>\n",
       "      <td>i at the unable to access the machine utilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>ufawcgob aowhxjky</td>\n",
       "      <td>GRP_62</td>\n",
       "      <td>en</td>\n",
       "      <td>i at the unable to access the machine utility ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>ufawcgob aowhxjky</td>\n",
       "      <td>GRP_62</td>\n",
       "      <td>en</td>\n",
       "      <td>i at the unable to access the machine utilitie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23537 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Caller Assignment group language  \\\n",
       "0     vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0     vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0     vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0     vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0     vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "...                 ...              ...      ...   \n",
       "8498  ufawcgob aowhxjky           GRP_62       en   \n",
       "8498  ufawcgob aowhxjky           GRP_62       en   \n",
       "8498  ufawcgob aowhxjky           GRP_62       en   \n",
       "8498  ufawcgob aowhxjky           GRP_62       en   \n",
       "8498  ufawcgob aowhxjky           GRP_62       en   \n",
       "\n",
       "                                             Final_Text  \n",
       "0     hello it's happened again The PC has been rele...  \n",
       "0     hello it's happen again The PC has been releas...  \n",
       "0     hello it's happened again The PC has been rele...  \n",
       "0     hello it's happened again The PC has be releas...  \n",
       "0     hello it's happened again The PC has been let ...  \n",
       "...                                                 ...  \n",
       "8498  i at the unable to access the machine utilitie...  \n",
       "8498  i at the unable to entree the machine utilitie...  \n",
       "8498  i at the unable to access the machine utilitie...  \n",
       "8498  i at the unable to access the machine utility ...  \n",
       "8498  i at the unable to access the machine utilitie...  \n",
       "\n",
       "[23537 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = new_dataframe.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug = new_dataframe.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated Text'],axis=1).join(s)\n",
    "new_dataframe_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "zcQ3e0XSBsjT",
    "outputId": "553f7564-546f-4629-810d-58ddff0cd2d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happen again The PC has been releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has be releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello it's happened again The PC has been let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gasbfqvp fmvqgjih</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>On my part, the password was incorrectly enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nizholae bjnqikym</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Stephryhan Needs Access to Below Collaboration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bmhrsxlf ukatbwyi</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>benefits issue benefits issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sjxhcyrq iupxtjcf</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Security Error in travel expenses Billing Prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>wfbkucds qaxhbois</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>I no longer know my ERP password and have fail...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Caller Assignment group language  \\\n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "..                 ...              ...      ...   \n",
       "87   gasbfqvp fmvqgjih            GRP_0       de   \n",
       "97   nizholae bjnqikym            GRP_0       de   \n",
       "100  bmhrsxlf ukatbwyi            GRP_0       de   \n",
       "101  sjxhcyrq iupxtjcf            GRP_0       de   \n",
       "104  wfbkucds qaxhbois            GRP_0       de   \n",
       "\n",
       "                                            Final_Text  \n",
       "0    hello it's happened again The PC has been rele...  \n",
       "0    hello it's happen again The PC has been releas...  \n",
       "0    hello it's happened again The PC has been rele...  \n",
       "0    hello it's happened again The PC has be releas...  \n",
       "0    hello it's happened again The PC has been let ...  \n",
       "..                                                 ...  \n",
       "87   On my part, the password was incorrectly enter...  \n",
       "97   Stephryhan Needs Access to Below Collaboration...  \n",
       "100                      benefits issue benefits issue  \n",
       "101  Security Error in travel expenses Billing Prog...  \n",
       "104  I no longer know my ERP password and have fail...  \n",
       "\n",
       "[27478 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframes=[clean_data_aug1,clean_data_aug2,clean_data_aug3,clean_aug4]\n",
    "#dataframes=[clean_data_aug1,clean_data_aug2,clean_data_aug3]\n",
    "zero_dataframe = zero_dataframe.rename(columns={\"Translated Text\": \"Final_Text\"})\n",
    "zero_dataframe = zero_dataframe.drop(['New Description', 'Clean_Description'], axis = 1)\n",
    "dataframes=[new_dataframe_aug, zero_dataframe]\n",
    "clean_data_result= pd.concat(dataframes)\n",
    "clean_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "BVwHlgzVBsjT",
    "outputId": "5608ed65-4877-4cb8-9d05-787d9bc84100"
   },
   "outputs": [],
   "source": [
    "# Assignment group distribution\n",
    "print('\\033[1mTotal assignment groups:\\033[0m', clean_data_result['Assignment group'].nunique())\n",
    "\n",
    "# Histogram\n",
    "clean_data_result['Assignment group'].iplot(\n",
    "    kind='hist',\n",
    "    xTitle='Assignment Group',\n",
    "    yTitle='count',\n",
    "    title='Assignment Group Distribution- Histogram (Fig-5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jFKf35cRQWq9"
   },
   "outputs": [],
   "source": [
    "# Serialize the Augmented dataset for later use\n",
    "clean_data_result.to_csv('Interim_data.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Interim_data.pkl','wb') as f:\n",
    "with open('Interim_data.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzxDdWyMBsjT"
   },
   "source": [
    "## Stop words removal and Lemmatise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSfE-xBvrFaY",
    "outputId": "75f73f34-0da0-4562-85f2-059ca9807595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caller                0\n",
       "Assignment group      0\n",
       "language              0\n",
       "Final_Text          197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6ZV6IfbOrFaZ"
   },
   "outputs": [],
   "source": [
    "clean_data_result['Final_Text'] = clean_data_result['Final_Text'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45rNIDGvBsjU",
    "outputId": "ad897777-03f2-4db9-82b4-77c0891e02c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aroy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "processed_all_documents = list()\n",
    "\n",
    "for desc in clean_data_result['Final_Text']:\n",
    "    word_tokens = word_tokenize(desc) \n",
    "    \n",
    "    filtered_sentence = [] \n",
    "\n",
    "    # Removing Stopwords\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    words = ' '.join(filtered_sentence)\n",
    "    processed_all_documents.append(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9Dh0hMMrrFaZ"
   },
   "outputs": [],
   "source": [
    "clean_data_result['Final_Text'] = processed_all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xn4waA6MBsjU",
    "outputId": "2a23d63e-2d78-45c3-b86f-11facacc2282"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happen The PC released repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC let go repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello Ben Tige Number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number Block keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number Block Keyboard R left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>IE browser opens CRM system , prompted user ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser open CRM system , prompted us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , motivate u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happen The PC released repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC let go repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello Ben Tige Number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number Block keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>Hello Ben Tige Number Block Keyboard R left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>IE browser opens CRM system , prompted user ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser open CRM system , prompted us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wtgbdjzl coliybmq</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>After IE browser opens CRM system , motivate u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello 's happen The PC released repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello 's happened The PC let go repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>hello Ben Tige Number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Hello Ben Tige number Block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Hello Ben Tige Number block Keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Hello Ben Tige Number Block keyboard R Left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>Hello Ben Tige Number Block Keyboard R left Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>IE browser opens CRM system , prompted user ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>After IE browser open CRM system , prompted us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>After IE browser opens CRM system , prompted u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjnlsbkq ocxnrewb</td>\n",
       "      <td>GRP_31</td>\n",
       "      <td>zh-cn</td>\n",
       "      <td>After IE browser opens CRM system , motivate u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lpnzjimy mwtvondq</td>\n",
       "      <td>GRP_25</td>\n",
       "      <td>de</td>\n",
       "      <td>current entered EU Tool Error Runtime Error EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lpnzjimy mwtvondq</td>\n",
       "      <td>GRP_25</td>\n",
       "      <td>de</td>\n",
       "      <td>Currents enter EU Tool Error Runtime Error EU ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lpnzjimy mwtvondq</td>\n",
       "      <td>GRP_25</td>\n",
       "      <td>de</td>\n",
       "      <td>Currents entered EU tool Error Runtime Error E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lpnzjimy mwtvondq</td>\n",
       "      <td>GRP_25</td>\n",
       "      <td>de</td>\n",
       "      <td>Currents entered EU Tool mistake Runtime mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lpnzjimy mwtvondq</td>\n",
       "      <td>GRP_25</td>\n",
       "      <td>de</td>\n",
       "      <td>Currents entered EU Tool mistake Runtime mista...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Caller Assignment group language  \\\n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  wtgbdjzl coliybmq           GRP_24       de   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "0  cjnlsbkq ocxnrewb           GRP_31    zh-cn   \n",
       "1  lpnzjimy mwtvondq           GRP_25       de   \n",
       "1  lpnzjimy mwtvondq           GRP_25       de   \n",
       "1  lpnzjimy mwtvondq           GRP_25       de   \n",
       "1  lpnzjimy mwtvondq           GRP_25       de   \n",
       "1  lpnzjimy mwtvondq           GRP_25       de   \n",
       "\n",
       "                                          Final_Text  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happen The PC released repeated times...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC let go repeated times...  \n",
       "0  hello Ben Tige Number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block Keyboard R left Ha...  \n",
       "0  IE browser opens CRM system , prompted user ca...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser open CRM system , prompted us...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser opens CRM system , motivate u...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happen The PC released repeated times...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC let go repeated times...  \n",
       "0  hello Ben Tige Number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block Keyboard R left Ha...  \n",
       "0  IE browser opens CRM system , prompted user ca...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser open CRM system , prompted us...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser opens CRM system , motivate u...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happen The PC released repeated times...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC released repeated tim...  \n",
       "0  hello 's happened The PC let go repeated times...  \n",
       "0  hello Ben Tige Number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige number Block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number block Keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block keyboard R Left Ha...  \n",
       "0  Hello Ben Tige Number Block Keyboard R left Ha...  \n",
       "0  IE browser opens CRM system , prompted user ca...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser open CRM system , prompted us...  \n",
       "0  After IE browser opens CRM system , prompted u...  \n",
       "0  After IE browser opens CRM system , motivate u...  \n",
       "1  current entered EU Tool Error Runtime Error EU...  \n",
       "1  Currents enter EU Tool Error Runtime Error EU ...  \n",
       "1  Currents entered EU tool Error Runtime Error E...  \n",
       "1  Currents entered EU Tool mistake Runtime mista...  \n",
       "1  Currents entered EU Tool mistake Runtime mista...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "UZ7s9d10EWG8",
    "outputId": "73fb5d09-7a32-42c7-ae50-230c16a5c289"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happen The PC released repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC released repeated tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello 's happened The PC let go repeated times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gasbfqvp fmvqgjih</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>On part , password incorrectly entered please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nizholae bjnqikym</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Stephryhan Needs Access Below Collaboration Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bmhrsxlf ukatbwyi</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>benefits issue benefits issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sjxhcyrq iupxtjcf</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Security Error travel expenses Billing Program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>wfbkucds qaxhbois</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>I longer know ERP password failed attempts go ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Caller Assignment group language  \\\n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "..                 ...              ...      ...   \n",
       "87   gasbfqvp fmvqgjih            GRP_0       de   \n",
       "97   nizholae bjnqikym            GRP_0       de   \n",
       "100  bmhrsxlf ukatbwyi            GRP_0       de   \n",
       "101  sjxhcyrq iupxtjcf            GRP_0       de   \n",
       "104  wfbkucds qaxhbois            GRP_0       de   \n",
       "\n",
       "                                            Final_Text  \n",
       "0    hello 's happened The PC released repeated tim...  \n",
       "0    hello 's happen The PC released repeated times...  \n",
       "0    hello 's happened The PC released repeated tim...  \n",
       "0    hello 's happened The PC released repeated tim...  \n",
       "0    hello 's happened The PC let go repeated times...  \n",
       "..                                                 ...  \n",
       "87   On part , password incorrectly entered please ...  \n",
       "97   Stephryhan Needs Access Below Collaboration Pl...  \n",
       "100                      benefits issue benefits issue  \n",
       "101  Security Error travel expenses Billing Program...  \n",
       "104  I longer know ERP password failed attempts go ...  \n",
       "\n",
       "[27478 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8YU9JQqEWG8",
    "outputId": "c79b258c-0198-4fac-9621-d18273efe22a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caller              0\n",
       "Assignment group    0\n",
       "language            0\n",
       "Final_Text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "H8t0_Di2EWG8"
   },
   "outputs": [],
   "source": [
    "clean_data_result['Final_Text'] = clean_data_result['Final_Text'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWJN-ekLBsjU",
    "outputId": "e1103eb4-fa06-4364-a0c4-4c4f550ed13b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com/simple, https://urm.nvidia.com/artifactory/api/pypi/sw-colossus-pypi/simple\n",
      "Requirement already satisfied: spacy in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (4.54.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (49.6.0.post20200814)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.19.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (7.4.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#Lemmatisation using spacy library\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WeoMfBEBBsjU",
    "outputId": "80a0bcc7-9bda-423b-b1be-55025e728b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com/simple, https://urm.nvidia.com/artifactory/api/pypi/sw-colossus-pypi/simple\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from en-core-web-sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (7.4.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.19.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (49.6.0.post20200814)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.54.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2020.11.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.1.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047113 sha256=2e3655aefcac3d591cfa31ffe961fff3be83dcc6522e8bc7631daf029c0b54d2\n",
      "  Stored in directory: c:\\users\\aroy\\appdata\\local\\pip\\cache\\wheels\\10\\6f\\a6\\ddd8204ceecdedddea923f8514e13afb0c1f0f556d2c9c3da0\n",
      "Successfully built en-core-web-sm\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HWRcbMrrOgn",
    "outputId": "8a8b340f-6bdc-4a82-8bfe-f0342375f48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com/simple, https://urm.nvidia.com/artifactory/api/pypi/sw-colossus-pypi/simple\n",
      "Requirement already satisfied: spacy in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (49.6.0.post20200814)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (7.4.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (4.54.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UAGj1FplBsjV"
   },
   "outputs": [],
   "source": [
    "# Need to run \"python -m spacy download en\" in anaconda prompt to avoid 'en' not found issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5Pxl8SyyBsjV"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "clean_data_result['Final_Text'] = clean_data_result['Final_Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "P0YLyD-iBsjV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc let go repeat time blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gasbfqvp fmvqgjih</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>on part , password incorrectly enter please pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nizholae bjnqikym</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Stephryhan need Access below Collaboration Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bmhrsxlf ukatbwyi</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>benefit issue benefit issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sjxhcyrq iupxtjcf</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Security Error travel expense Billing ProgramD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>wfbkucds qaxhbois</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>-PRON- long know ERP password fail attempt go ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Caller Assignment group language  \\\n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "..                 ...              ...      ...   \n",
       "87   gasbfqvp fmvqgjih            GRP_0       de   \n",
       "97   nizholae bjnqikym            GRP_0       de   \n",
       "100  bmhrsxlf ukatbwyi            GRP_0       de   \n",
       "101  sjxhcyrq iupxtjcf            GRP_0       de   \n",
       "104  wfbkucds qaxhbois            GRP_0       de   \n",
       "\n",
       "                                            Final_Text  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc let go repeat time blue...  \n",
       "..                                                 ...  \n",
       "87   on part , password incorrectly enter please pa...  \n",
       "97   Stephryhan need Access below Collaboration Pla...  \n",
       "100                        benefit issue benefit issue  \n",
       "101  Security Error travel expense Billing ProgramD...  \n",
       "104  -PRON- long know ERP password fail attempt go ...  \n",
       "\n",
       "[27478 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "3yJf4QCZaoah"
   },
   "outputs": [],
   "source": [
    "# Serialize the translated dataset\n",
    "clean_data_result.to_csv('Final_data.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Final_data.pkl','wb') as f:\n",
    "with open('Final_data.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e-zXZRYDaoah"
   },
   "outputs": [],
   "source": [
    "# Load the translated pickle file \n",
    "#with open('/content/Final_data.pkl','rb') as f:\n",
    "with open('Final_data.pkl','rb') as f:\n",
    "    clean_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MufrYo4zaoah"
   },
   "source": [
    "### Univariate visualization\n",
    "Single-variable or univariate visualization is the simplest type of visualization which consists of observations on only a single characteristic or attribute. Univariate visualization includes histogram, bar plots and line charts.\n",
    "\n",
    "#### The distribution of Assignment groups\n",
    "Plots how the assignments groups are scattered across the dataset. The bar chart, histogram and pie chart tells the frequency of any ticket assigned to any group OR the tickets count for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEzuZQTdaoah"
   },
   "outputs": [],
   "source": [
    "# Assignment group distribution\n",
    "print('\\033[1mTotal assignment groups:\\033[0m', clean_data['Assignment group'].nunique())\n",
    "\n",
    "# Histogram\n",
    "clean_data['Assignment group'].iplot(\n",
    "    kind='hist',\n",
    "    xTitle='Assignment Group',\n",
    "    yTitle='count',\n",
    "    title='Assignment Group Distribution- Histogram (Fig-1)')\n",
    "\n",
    "# Pie chart\n",
    "assgn_grp = pd.DataFrame(clean_data.groupby('Assignment group').size(),columns = ['Count']).reset_index()\n",
    "assgn_grp.iplot(\n",
    "    kind='pie', \n",
    "    labels='Assignment group', \n",
    "    values='Count', \n",
    "    title='Assignment Group Distribution- Pie Chart (Fig-2)', \n",
    "    hoverinfo=\"label+percent+name\", hole=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Hn2Iwq_aoah"
   },
   "source": [
    "### Lets visualize the percentage of incidents per assignment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw4H53FGaoah"
   },
   "outputs": [],
   "source": [
    "# Plot to visualize the percentage data distribution across different groups\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,5))\n",
    "ax = sns.countplot(x=\"Assignment group\", data=clean_data, order=clean_data[\"Assignment group\"].value_counts().index)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(format(p.get_height()/len(clean_data.index)*100, '.2f')+\"%\"), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'bottom', rotation=90, xytext = (0, 10), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HRA85rBaoah"
   },
   "outputs": [],
   "source": [
    "top_20 = clean_data['Assignment group'].value_counts().nlargest(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mk193_BAaoah"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(top_20['index'],top_20['Assignment group'])\n",
    "plt.title('Top 20 Assignment groups with highest number of Tickets')\n",
    "plt.xlabel('Assignment Group')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of Tickets')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + .005, yval)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL1odSqxaoah"
   },
   "outputs": [],
   "source": [
    "bottom_20 = clean_data['Assignment group'].value_counts().nsmallest(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKTbEME0aoah"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "bars = plt.bar(bottom_20['index'],bottom_20['Assignment group'])\n",
    "plt.title('Bottom 20 Assignment groups with small number of Tickets')\n",
    "plt.xlabel('Assignment Group')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of Tickets')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + .005, yval)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTEdYvB4aoah"
   },
   "source": [
    "#### The distribution of Callers\n",
    "Plots how the callers are associated with tickets and what are the assignment groups they most frequently raise tickets for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DF-i2z1aoah"
   },
   "outputs": [],
   "source": [
    "# Find out top 10 callers in terms of frequency of raising tickets in the entire dataset\n",
    "print('\\033[1mTotal caller count:\\033[0m', clean_data['Caller'].nunique())\n",
    "df = pd.DataFrame(clean_data.groupby(['Caller']).size().nlargest(10), columns=['Count']).reset_index()\n",
    "df.iplot(kind='pie',\n",
    "         labels='Caller', \n",
    "         values='Count', \n",
    "         title='Top 10 caller- Pie Chart (Fig-7)',\n",
    "         colorscale='-spectral',\n",
    "         pull=[0,0,0,0,0.05,0.1,0.15,0.2,0.25,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTiANuJnaoah"
   },
   "outputs": [],
   "source": [
    "# Top 5 callers in each assignment group\n",
    "top_n = 5\n",
    "s = clean_data['Caller'].groupby(clean_data['Assignment group']).value_counts()\n",
    "caller_grp = pd.DataFrame(s.groupby(level=0).nlargest(top_n).reset_index(level=0, drop=True))\n",
    "caller_grp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbHn-V3Maoah"
   },
   "source": [
    "#### The distribution of description lengths\n",
    "Plots the variation of length and word count of new description attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdrJgg48aoai"
   },
   "outputs": [],
   "source": [
    "clean_data.insert(1, 'desc_len', clean_data['Final_Text'].astype(str).apply(len))\n",
    "clean_data.insert(5, 'desc_word_count', clean_data['Final_Text'].apply(lambda x: len(str(x).split())))\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38p2Thiaaoai"
   },
   "outputs": [],
   "source": [
    "# Description text length\n",
    "clean_data['desc_len'].iplot(\n",
    "    kind='bar',\n",
    "    xTitle='text length',\n",
    "    yTitle='count',\n",
    "    colorscale='-ylgn',\n",
    "    title='Description Text Length Distribution (Fig-11)')\n",
    "\n",
    "# Description word count\n",
    "clean_data['desc_word_count'].iplot(\n",
    "    kind='bar',\n",
    "    xTitle='word count',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    colorscale='-bupu',\n",
    "    title='Description Word Count Distribution (Fig-12)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qTz5tP8aoai"
   },
   "source": [
    "### N-Grams\n",
    "N-gram is a contiguous sequence of N items from a given sample of text or speech, in the fields of computational linguistics and probability. The items can be phonemes, syllables, letters, words or base pairs according to the application. N-grams are used to describe the number of words used as observation points, e.g., unigram means singly-worded, bigram means 2-worded phrase, and trigram means 3-worded phrase. \n",
    "\n",
    "We'll be using scikit-learn’s CountVectorizer function to derive n-grams and compare them before and after removing stop words. Stop words are a set of commonly used words in any language. We'll be using english corpus stopwords and extend it to include some business specific common words considered to be stop words in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c0ivkwEaoai"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Extend the English Stop Wordss\n",
    "STOP_WORDS = STOPWORDS.union({'yes','na','hi',\n",
    "                              'receive','hello',\n",
    "                              'regards','thanks',\n",
    "                              'from','greeting',\n",
    "                              'forward','reply',\n",
    "                              'will','please',\n",
    "                              'see','help','able'})\n",
    "\n",
    "# Generic function to derive top N n-grams from the corpus\n",
    "def get_top_n_ngrams(corpus, top_n=None, ngram_range=(1,1), stopwords=None):\n",
    "    vec = CountVectorizer(ngram_range=ngram_range, \n",
    "                          stop_words=stopwords).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BaGo4WSaoai"
   },
   "source": [
    "### Top Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pejZdQiTaoai"
   },
   "outputs": [],
   "source": [
    "# Top 50 Unigrams before removing stop words\n",
    "top_n = 50\n",
    "ngram_range = (1,1)\n",
    "uni_grams = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range)\n",
    "\n",
    "df = pd.DataFrame(uni_grams, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    colorscale='piyg',\n",
    "    title=f'Top {top_n} Unigrams in Final_Text')\n",
    "\n",
    "# Top 50 Unigrams after removing stop words\n",
    "uni_grams_sw = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range, stopwords=STOP_WORDS)\n",
    "\n",
    "df = pd.DataFrame(uni_grams_sw, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black',\n",
    "    colorscale='-piyg',\n",
    "    title=f'Top {top_n} Unigrams in Final_Text without stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb8iWkH-aoai"
   },
   "source": [
    "### Top Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qrr4qJNaoai"
   },
   "outputs": [],
   "source": [
    "# Top 50 Bigrams before removing stop words\n",
    "top_n = 50\n",
    "ngram_range = (2,2)\n",
    "bi_grams = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range)\n",
    "\n",
    "df = pd.DataFrame(bi_grams, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    colorscale='piyg',\n",
    "    title=f'Top {top_n} Bigrams in Final_Text')\n",
    "\n",
    "# Top 50 Bigrams after removing stop words\n",
    "bi_grams_sw = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range, stopwords=STOP_WORDS)\n",
    "\n",
    "df = pd.DataFrame(bi_grams_sw, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black',\n",
    "    colorscale='-piyg',\n",
    "    title=f'Top {top_n} Bigrams in Final_Text without stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc62MwL5aoai"
   },
   "source": [
    "### Top Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LE3n2E_zaoai"
   },
   "outputs": [],
   "source": [
    "# Top 50 Trigrams before removing stop words\n",
    "top_n = 50\n",
    "ngram_range = (3,3)\n",
    "tri_grams = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range)\n",
    "\n",
    "df = pd.DataFrame(tri_grams, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black', \n",
    "    colorscale='piyg',\n",
    "    title=f'Top {top_n} Trigrams in Final_Text')\n",
    "\n",
    "# Top 50 Trigrams after removing stop words\n",
    "tri_grams_sw = get_top_n_ngrams(clean_data.Final_Text, top_n, ngram_range, stopwords=STOP_WORDS)\n",
    "\n",
    "df = pd.DataFrame(tri_grams_sw, columns = ['Final_Text' , 'count'])\n",
    "df.groupby('Final_Text').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', \n",
    "    yTitle='Count', \n",
    "    linecolor='black',\n",
    "    colorscale='-piyg',\n",
    "    title=f'Top {top_n} Trigrams in Final_Text without stop words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4hSbsitaoai"
   },
   "source": [
    "### Word Cloud\n",
    "Let us attempt to visualize this as a word cloud for top three groups that has got maximum records. A word cloud enables us to visualize the data as cluster of words and each words displayed in different font size based on the number of occurences of that word . Basically; the bolder and bigger the word show up in the visualization, it implies its more often it’s mentioned within a given text compared to other words in the cloud and therefore would be more important for us.\n",
    "\n",
    "Let's write a generic method to generate Word Clouds for both Short and Long Description columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoPIxAzmEWHI"
   },
   "outputs": [],
   "source": [
    "# replace any single word character with a word boundary\n",
    "#clean_data.Final_Text.str.replace(r'\\b\\w\\b','').str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKttDbCQaoai"
   },
   "outputs": [],
   "source": [
    "def generate_word_cloud(corpus):\n",
    "        # Instantiate the wordcloud object\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    stopwords=STOP_WORDS,\n",
    "                    # mask=mask,\n",
    "                    min_font_size = 10).generate(corpus)\n",
    "\n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (12, 12), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKpk_Grwaoai"
   },
   "outputs": [],
   "source": [
    "# Word Cloud for all tickets assigned to GRP_0\n",
    "generate_word_cloud(' '.join(clean_data[clean_data['Assignment group'] == 'GRP_0'].Final_Text.str.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJkOwVhbaoai"
   },
   "outputs": [],
   "source": [
    "# Word Cloud for all tickets assigned to GRP_8\n",
    "generate_word_cloud(' '.join(clean_data[clean_data['Assignment group'] == 'GRP_8'].Final_Text.str.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLQhXr6Yaoai"
   },
   "outputs": [],
   "source": [
    "# Word Cloud for all tickets assigned to GRP_25\n",
    "generate_word_cloud(' '.join(clean_data[clean_data['Assignment group'] == 'GRP_25'].Final_Text.str.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IqWo_cPaoai",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate wordcloud for Final_Text field\n",
    "generate_word_cloud(' '.join(clean_data.Final_Text.str.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhCUgD6_Bsjn"
   },
   "source": [
    "## Prepping Dataframe for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tb8URlQ4Z85A"
   },
   "outputs": [],
   "source": [
    "'''# Create a target categorical column\n",
    "clean_data['Assignment group OneHotEncoded'] = clean_data['Assignment group'].astype('category').cat.codes\n",
    "clean_data.info()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FW9b_WeCBsjn"
   },
   "outputs": [],
   "source": [
    "'''# Import OneHot encoder \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import preprocessing \n",
    "clean_data['Assignment group OneHotEncoded'] = np.nan\n",
    "# OneHot_encoder object knows how to understand word labels. \n",
    "#onehot_encoder = preprocessing.OneHotEncoder() #categories=62\n",
    "onehot_encoder = LabelBinarizer()\n",
    "onehot_encoder.fit(clean_data['Assignment group'])\n",
    "# Encode labels in column\n",
    "#transformed = onehot_encoder.fit_transform(clean_data['Assignment group'])\n",
    "#temp_df = pd.DataFrame(transformed, columns=onehot_encoder.get_feature_names())\n",
    "transformed = onehot_encoder.transform(clean_data['Assignment group'])\n",
    "temp_df = pd.DataFrame(transformed)\n",
    "clean_data = pd.concat([clean_data, temp_df], axis=1)\n",
    "#clean_data\n",
    "#clean_data['Assignment group OneHotEncoded'].unique()\n",
    "clean_data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9ijBA6KgW13C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc release repeat time blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrfpyjwi nzhvgqiw</td>\n",
       "      <td>GRP_24</td>\n",
       "      <td>de</td>\n",
       "      <td>hello be happen the pc let go repeat time blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gasbfqvp fmvqgjih</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>on part , password incorrectly enter please pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nizholae bjnqikym</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Stephryhan need Access below Collaboration Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bmhrsxlf ukatbwyi</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>benefit issue benefit issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sjxhcyrq iupxtjcf</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>Security Error travel expense Billing ProgramD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>wfbkucds qaxhbois</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>de</td>\n",
       "      <td>-PRON- long know ERP password fail attempt go ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Caller Assignment group language  \\\n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "0    vrfpyjwi nzhvgqiw           GRP_24       de   \n",
       "..                 ...              ...      ...   \n",
       "87   gasbfqvp fmvqgjih            GRP_0       de   \n",
       "97   nizholae bjnqikym            GRP_0       de   \n",
       "100  bmhrsxlf ukatbwyi            GRP_0       de   \n",
       "101  sjxhcyrq iupxtjcf            GRP_0       de   \n",
       "104  wfbkucds qaxhbois            GRP_0       de   \n",
       "\n",
       "                                            Final_Text  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc release repeat time blu...  \n",
       "0    hello be happen the pc let go repeat time blue...  \n",
       "..                                                 ...  \n",
       "87   on part , password incorrectly enter please pa...  \n",
       "97   Stephryhan need Access below Collaboration Pla...  \n",
       "100                        benefit issue benefit issue  \n",
       "101  Security Error travel expense Billing ProgramD...  \n",
       "104  -PRON- long know ERP password fail attempt go ...  \n",
       "\n",
       "[27478 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FRguKfOkEWHJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 25, 18,  4, 35, 26, 24, 32, 21,  1,  8, 12, 27, 13,  6, 23,  2,\n",
       "       22, 29,  5, 42, 36, 19, 34, 37, 40, 41, 10,  3,  7,  9, 11, 14, 15,\n",
       "       16, 20, 28, 30, 31, 33, 38, 39,  0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "clean_data['Assignment group LabelEncoded']= label_encoder.fit_transform(clean_data['Assignment group']) \n",
    "  \n",
    "clean_data['Assignment group LabelEncoded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6jsBDjGIBsjn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoded_dict = dict(zip(clean_data['Assignment group'].unique(), clean_data['Assignment group LabelEncoded'].unique()))\n",
    "len(label_encoded_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha-VhcWRBsjn"
   },
   "source": [
    "## Feature Extraction : Bag of Words using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "n3UGzor_Bsjo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Feature : (27478, 2000)\n",
      "Shape of Target Feature : (27478,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CV = CountVectorizer(max_features=2000)\n",
    "\n",
    "X_BoW = CV.fit_transform(clean_data['Final_Text']).toarray()\n",
    "y = clean_data['Assignment group LabelEncoded']\n",
    "\n",
    "print(\"Shape of Input Feature :\",np.shape(X_BoW))\n",
    "print(\"Shape of Target Feature :\",np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UaaV3zyqBsjo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of the training set:\u001b[0m (19234, 2000) (8244, 2000)\n",
      "\u001b[1mShape of the test set:\u001b[0m (19234,) (8244,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_BoW, y, test_size=0.3, random_state = 0, stratify=y)\n",
    "print('\\033[1mShape of the training set:\\033[0m', X_train.shape, X_test.shape)\n",
    "print('\\033[1mShape of the test set:\\033[0m', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EIni9BjpBsjo"
   },
   "outputs": [],
   "source": [
    "def run_classification(estimator, X_train, X_test, y_train, y_test, arch_name=None, pipelineRequired=True, isDeepModel=False):\n",
    "    # train the model\n",
    "    clf = estimator\n",
    "\n",
    "    if pipelineRequired :\n",
    "        clf = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                     ('clf', estimator),\n",
    "                     ])\n",
    "      \n",
    "    if isDeepModel :\n",
    "        clf.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=25, batch_size=128,verbose=1,callbacks=call_backs(arch_name))\n",
    "        # predict from the clasiffier\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "    else :\n",
    "        clf.fit(X_train, y_train)\n",
    "        # predict from the clasiffier\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "    \n",
    "    print('Estimator:', clf)\n",
    "    print('='*80)\n",
    "    print('Training accuracy: %.2f%%' % (accuracy_score(y_train,y_train_pred) * 100))\n",
    "    print('Testing accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "    print('='*80)\n",
    "    print('Confusion matrix:\\n %s' % (confusion_matrix(y_test, y_pred)))\n",
    "    print('='*80)\n",
    "    print('Classification report:\\n %s' % (classification_report(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxlH4wqyBsjo"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_RXTWZfBsjp"
   },
   "outputs": [],
   "source": [
    "run_classification(LogisticRegression(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7r6p2SGBsjp"
   },
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hlgbYXyBsjp"
   },
   "outputs": [],
   "source": [
    "run_classification(MultinomialNB(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs5ztA2kBsjp"
   },
   "source": [
    "## K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl6W5gZ0emJG"
   },
   "source": [
    "#### Applying Gridsearch to find Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNaUF44hemJG",
    "outputId": "52f1495b-c11d-46e6-ddb9-a5b39f4dc029"
   },
   "outputs": [],
   "source": [
    "param = {'n_neighbors': [3,5,7], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), param, verbose = 1, cv = 3, n_jobs = -1)\n",
    "gs_knn_results = gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIlmMBOqemJG",
    "outputId": "9b7fd151-93e6-4137-8adf-22250620adcb"
   },
   "outputs": [],
   "source": [
    "gs_knn_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ln2C3uvcemJG",
    "outputId": "6a30f8c1-b57d-45b6-cc1b-57cb074bfa7d"
   },
   "outputs": [],
   "source": [
    "gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdMOT5TGemJH",
    "outputId": "ff37a2ea-5249-436b-e729-078a626f6517"
   },
   "outputs": [],
   "source": [
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTcSwEXnemJH",
    "outputId": "b9f870c4-a28f-4b85-e5cd-50b1e016c95b"
   },
   "outputs": [],
   "source": [
    "knn_clf = gs_knn.best_estimator_\n",
    "\n",
    "run_classification(knn_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4qwMKt7Bsjq"
   },
   "outputs": [],
   "source": [
    "#run_classification(KNeighborsClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDMha2lxBsjq"
   },
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6zuFD4vemJH"
   },
   "source": [
    "#### Applying Gridsearch to find Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH4y5e5bemJH"
   },
   "outputs": [],
   "source": [
    "?SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "jBc7yY11Bsjq"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a6d7c04a18ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgs_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgs_svm_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    274\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "param = {'C':[0.5,1,2.5],'kernel':['linear','rbf']}\n",
    "gs_svm = GridSearchCV (model,param_grid=param, cv=3,scoring ='accuracy')\n",
    "gs_svm_results = gs_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLVn5mGAemJI",
    "outputId": "9882c0aa-bda7-4351-e513-4f37b1f7fb1a"
   },
   "outputs": [],
   "source": [
    "gs_svm_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gg7IsKUJemJI",
    "outputId": "c3891334-d52b-4304-e541-f1335f640ca1"
   },
   "outputs": [],
   "source": [
    "gs_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qf-uoC1iemJI",
    "outputId": "40195575-fe8b-447e-b4e3-b8934d59d305"
   },
   "outputs": [],
   "source": [
    "gs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZy8FdhkemJI",
    "outputId": "0ef8c2f3-8f44-4f94-d5ee-75efc2c7dae9"
   },
   "outputs": [],
   "source": [
    "svc_clf = gs_svm.best_estimator_\n",
    "\n",
    "run_classification(svc_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDPisp5SBsjq"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fIyUSOBemJJ"
   },
   "outputs": [],
   "source": [
    "#Using GRIDSearch CV to find hyper parameters\n",
    "\n",
    "params = {'criterion': ['entropy', 'gini'], 'max_depth': [None,3,4,5,9,10 ],            \n",
    "               'min_samples_leaf': [ 2, 3, 5,7, 10,20]}\n",
    "DTreg = DecisionTreeClassifier()\n",
    "gs_DT = GridSearchCV(estimator = DTreg,\n",
    "                           param_grid = params,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,)\n",
    "gs_DT_results = gs_DT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_XaKRd6emJJ",
    "outputId": "57a4e1b0-d402-47e5-cd38-ef5d521dcb59"
   },
   "outputs": [],
   "source": [
    "#Using GRIDSearch CV to find hyper parameters\n",
    "\n",
    "gs_DT_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQImxb58csKt",
    "outputId": "ee2eb751-eb70-496c-e9cc-31c08db93495"
   },
   "outputs": [],
   "source": [
    "gs_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X3W94JLNemJJ",
    "outputId": "dc82837a-cd55-4e1b-ce9c-7fcaedfc5c78"
   },
   "outputs": [],
   "source": [
    "gs_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toOhHjfuemJJ"
   },
   "outputs": [],
   "source": [
    "DT_clf = gs_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuikGfJ0emJJ",
    "outputId": "d46bdc40-7112-4d30-e168-99b576c02ac0"
   },
   "outputs": [],
   "source": [
    "run_classification(DT_clf,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyvv2qn5Bsjq"
   },
   "outputs": [],
   "source": [
    "#run_classification(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpJIipnsBsjr"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FTzHUqQ6VoJ5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "7lNJTrV7V03u",
    "outputId": "5db71334-0065-4cdc-efeb-25193cef527c"
   },
   "outputs": [],
   "source": [
    "#Using RandomizedSearchCV (GRIDSearch is taing longer) to find hyper parameters\n",
    "\n",
    "params = {'n_estimators': [75, 100, 250,500], 'max_depth': [3,5,10,15,25]}\n",
    "rfc = RandomForestClassifier(class_weight = 'balanced', n_jobs=1)\n",
    "rs_rfc = RandomizedSearchCV(estimator = rfc,\n",
    "                           param_distributions = params,\n",
    "                           cv = 3,random_state = 42, n_jobs = 1, return_train_score= True)\n",
    "rs_rfc_results = rs_rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "vHCtNw_yXYKQ",
    "outputId": "1b94873f-2ab0-467f-aaad-88d280acc357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5571905031443053"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rfc_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7fzcdelrXTpe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_depth': 25}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iNilKG5kXT0F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=250,\n",
       "                       n_jobs=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "L8TT0dNXXqPg"
   },
   "outputs": [],
   "source": [
    "rfc_clf = rs_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "eydi_CqFX9lb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                                        n_estimators=250, n_jobs=1))])\n",
      "================================================================================\n",
      "Training accuracy: 63.11%\n",
      "Testing accuracy: 56.91%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[604   0   9 ...   9   2   0]\n",
      " [  0  30   0 ...   0   0   0]\n",
      " [  0   0 125 ...   0   0  11]\n",
      " ...\n",
      " [  0   0   0 ...  85   0   0]\n",
      " [  0   0   4 ...   0 362 110]\n",
      " [  4   0   0 ...   0   0 157]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.51      0.67      1182\n",
      "           1       0.79      0.65      0.71        46\n",
      "           2       0.82      0.68      0.74       184\n",
      "           3       0.64      0.94      0.76        48\n",
      "           4       0.81      0.57      0.67       503\n",
      "           5       0.74      0.86      0.80       225\n",
      "           6       0.84      0.90      0.87       184\n",
      "           7       0.94      1.00      0.97        58\n",
      "           8       0.74      0.85      0.79       134\n",
      "           9       0.67      1.00      0.80        37\n",
      "          10       0.84      0.96      0.90       135\n",
      "          11       0.62      0.77      0.69       310\n",
      "          12       0.75      0.73      0.74       313\n",
      "          13       0.95      0.91      0.93        58\n",
      "          14       0.80      0.95      0.87        43\n",
      "          15       0.55      0.98      0.70        46\n",
      "          16       0.86      1.00      0.92        37\n",
      "          17       0.61      0.19      0.29       814\n",
      "          18       0.65      0.60      0.63       245\n",
      "          19       0.44      0.81      0.57        91\n",
      "          20       0.39      0.93      0.55        27\n",
      "          21       0.49      0.54      0.51       107\n",
      "          22       0.89      0.86      0.88       151\n",
      "          23       0.85      0.57      0.69       298\n",
      "          24       0.14      0.31      0.19       131\n",
      "          25       0.27      0.48      0.34       129\n",
      "          26       0.48      0.15      0.23       483\n",
      "          27       0.35      0.62      0.45       138\n",
      "          28       0.77      1.00      0.87        24\n",
      "          29       0.94      0.79      0.86       151\n",
      "          30       0.81      0.96      0.88        67\n",
      "          31       0.91      1.00      0.95        60\n",
      "          32       0.27      0.18      0.22       214\n",
      "          33       0.79      0.83      0.81        46\n",
      "          34       0.59      0.76      0.67        34\n",
      "          35       0.05      0.67      0.10       105\n",
      "          36       0.32      0.44      0.37       127\n",
      "          37       0.78      0.50      0.61       196\n",
      "          38       0.35      0.61      0.45        18\n",
      "          39       0.86      0.86      0.86        29\n",
      "          40       0.87      0.82      0.84       104\n",
      "          41       0.99      0.55      0.70       662\n",
      "          42       0.38      0.63      0.48       250\n",
      "\n",
      "    accuracy                           0.57      8244\n",
      "   macro avg       0.66      0.72      0.66      8244\n",
      "weighted avg       0.71      0.57      0.60      8244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification(rfc_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b28KjuoBsjr"
   },
   "outputs": [],
   "source": [
    "#run_classification(RandomForestClassifier(n_estimators=100, random_state=0), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOuKESHfrFai"
   },
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RJr4CJMBBsjr"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#run_classification(GradientBoostingClassifier(n_estimators=100, random_state=0), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AHedo7snYqKI"
   },
   "outputs": [],
   "source": [
    "params ={'max_depth':[3,5,10,15],'n_estimators':[5,10,30,50,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "4g27jdY5YqRH",
    "outputId": "e7238bbd-6e24-473b-b649-2d44d855ae15"
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "rs_gbc = RandomizedSearchCV(estimator = gbc,\n",
    "                           param_distributions = params,\n",
    "                           cv = 3,random_state = 42, n_jobs = 1, return_train_score= True)\n",
    "#Fitting randomsearch model\n",
    "rs_gbc_results = rs_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EIMcv7IIYqVr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6972551271388764"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_gbc_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xOgbxXObYqcG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50, 'max_depth': 15}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "JW48Nhc_Yqgj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=15, n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_gbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "1907hVmWYqls"
   },
   "outputs": [],
   "source": [
    "gbc_clf = rs_gbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ljgEYIOJYqtS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 GradientBoostingClassifier(max_depth=15, n_estimators=50,\n",
      "                                            random_state=42))])\n",
      "================================================================================\n",
      "Training accuracy: 81.88%\n",
      "Testing accuracy: 71.18%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[968   0   3 ...   3   1   4]\n",
      " [  0  31   0 ...   0   3   0]\n",
      " [  0   0 149 ...   0  13   0]\n",
      " ...\n",
      " [  1   0   0 ...  90   0   0]\n",
      " [  1   0   4 ...   0 551   2]\n",
      " [  3   0   0 ...   0  88  96]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1182\n",
      "           1       0.66      0.67      0.67        46\n",
      "           2       0.79      0.81      0.80       184\n",
      "           3       0.76      0.85      0.80        48\n",
      "           4       0.75      0.70      0.72       503\n",
      "           5       0.97      0.89      0.93       225\n",
      "           6       0.92      0.91      0.91       184\n",
      "           7       0.93      0.93      0.93        58\n",
      "           8       0.78      0.89      0.83       134\n",
      "           9       0.84      0.86      0.85        37\n",
      "          10       0.98      0.93      0.95       135\n",
      "          11       0.95      0.94      0.95       310\n",
      "          12       0.87      0.82      0.84       313\n",
      "          13       0.95      0.90      0.92        58\n",
      "          14       0.89      0.95      0.92        43\n",
      "          15       0.90      0.98      0.94        46\n",
      "          16       0.88      1.00      0.94        37\n",
      "          17       0.48      0.61      0.54       814\n",
      "          18       0.66      0.69      0.68       245\n",
      "          19       0.81      0.79      0.80        91\n",
      "          20       0.87      0.74      0.80        27\n",
      "          21       0.54      0.56      0.55       107\n",
      "          22       0.83      0.83      0.83       151\n",
      "          23       0.92      0.88      0.90       298\n",
      "          24       0.15      0.11      0.12       131\n",
      "          25       0.48      0.36      0.41       129\n",
      "          26       0.44      0.46      0.45       483\n",
      "          27       0.46      0.59      0.52       138\n",
      "          28       0.88      0.96      0.92        24\n",
      "          29       0.94      0.86      0.90       151\n",
      "          30       0.87      0.91      0.89        67\n",
      "          31       0.94      1.00      0.97        60\n",
      "          32       0.38      0.33      0.35       214\n",
      "          33       1.00      0.76      0.86        46\n",
      "          34       1.00      0.65      0.79        34\n",
      "          35       0.09      0.09      0.09       105\n",
      "          36       0.48      0.41      0.44       127\n",
      "          37       0.71      0.55      0.62       196\n",
      "          38       0.90      0.50      0.64        18\n",
      "          39       1.00      0.76      0.86        29\n",
      "          40       0.91      0.87      0.89       104\n",
      "          41       0.68      0.83      0.75       662\n",
      "          42       0.72      0.38      0.50       250\n",
      "\n",
      "    accuracy                           0.71      8244\n",
      "   macro avg       0.76      0.73      0.74      8244\n",
      "weighted avg       0.72      0.71      0.71      8244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification(gbc_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-lWxfbVrFai"
   },
   "source": [
    "## XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "wIYQ2WZJrFai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com/simple, https://urm.nvidia.com/artifactory/api/pypi/sw-colossus-pypi/simple\n",
      "Requirement already satisfied: xgboost in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: scipy in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\aroy\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (1.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8q7-fcTurFai"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#run_classification(XGBClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "qemvCs0Yauw8"
   },
   "outputs": [],
   "source": [
    "params ={'max_depth':[3,5,10,15],'n_estimators':[5,10,30,50,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Hm9sRUmQau1R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroy\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:35:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:35:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:37:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:39:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:11:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:43:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:44:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:22:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:27:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:33:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:33:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:35:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:38:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:40:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:00:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:00:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:20:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:39:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:43:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:54:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:01:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:20:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:21:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:44:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:45:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:40:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:34:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:30:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:40:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:41:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[08:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier(class_weight ='balanced', n_jobs=1)\n",
    "rs_xgbc = RandomizedSearchCV(estimator = xgbc,\n",
    "                           param_distributions = params,\n",
    "                           cv = 3,random_state = 42, n_jobs = 1, return_train_score= True)\n",
    "#Fitting randomsearch model\n",
    "rs_xgbc_results = rs_xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "sWGHN1flau6O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107206325139271"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgbc_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ovne63g-au-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50, 'max_depth': 15}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IMIhJ4XTavD4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=15, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=1,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "TVHTb5SYavJB"
   },
   "outputs": [],
   "source": [
    "xgbc_clf = rs_xgbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3Q4-HK-EavQ9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroy\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:31:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Estimator: Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               class_weight='balanced', colsample_bylevel=1,\n",
      "                               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "                               gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=15, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=50,\n",
      "                               n_jobs=1, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "================================================================================\n",
      "Training accuracy: 81.70%\n",
      "Testing accuracy: 72.68%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[1014    0    3 ...    1    2    3]\n",
      " [   0   30    0 ...    0    3    0]\n",
      " [   1    0  145 ...    0   14    0]\n",
      " ...\n",
      " [   3    0    0 ...   95    0    0]\n",
      " [   0    0    4 ...    0  553    2]\n",
      " [   3    0    0 ...    0   88   96]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      1182\n",
      "           1       0.64      0.65      0.65        46\n",
      "           2       0.82      0.79      0.81       184\n",
      "           3       0.80      0.85      0.83        48\n",
      "           4       0.70      0.72      0.71       503\n",
      "           5       0.95      0.91      0.93       225\n",
      "           6       0.91      0.92      0.92       184\n",
      "           7       0.95      0.98      0.97        58\n",
      "           8       0.82      0.94      0.88       134\n",
      "           9       0.95      1.00      0.97        37\n",
      "          10       0.97      0.93      0.95       135\n",
      "          11       0.89      0.93      0.91       310\n",
      "          12       0.86      0.83      0.84       313\n",
      "          13       0.98      0.90      0.94        58\n",
      "          14       0.98      0.95      0.96        43\n",
      "          15       0.94      0.98      0.96        46\n",
      "          16       0.90      1.00      0.95        37\n",
      "          17       0.48      0.64      0.55       814\n",
      "          18       0.72      0.70      0.71       245\n",
      "          19       0.85      0.78      0.81        91\n",
      "          20       1.00      0.67      0.80        27\n",
      "          21       0.59      0.55      0.57       107\n",
      "          22       0.87      0.89      0.88       151\n",
      "          23       0.90      0.90      0.90       298\n",
      "          24       0.18      0.09      0.12       131\n",
      "          25       0.52      0.35      0.42       129\n",
      "          26       0.45      0.46      0.45       483\n",
      "          27       0.56      0.59      0.58       138\n",
      "          28       1.00      0.96      0.98        24\n",
      "          29       0.94      0.88      0.91       151\n",
      "          30       0.93      0.94      0.93        67\n",
      "          31       0.97      1.00      0.98        60\n",
      "          32       0.42      0.35      0.38       214\n",
      "          33       0.95      0.83      0.88        46\n",
      "          34       1.00      0.68      0.81        34\n",
      "          35       0.09      0.08      0.08       105\n",
      "          36       0.50      0.40      0.45       127\n",
      "          37       0.73      0.55      0.63       196\n",
      "          38       0.90      0.50      0.64        18\n",
      "          39       0.87      0.93      0.90        29\n",
      "          40       0.92      0.91      0.92       104\n",
      "          41       0.66      0.84      0.74       662\n",
      "          42       0.83      0.38      0.52       250\n",
      "\n",
      "    accuracy                           0.73      8244\n",
      "   macro avg       0.79      0.74      0.76      8244\n",
      "weighted avg       0.73      0.73      0.72      8244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification(xgbc_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MizYVnZrFai"
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "KPuCWrZGrFai"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "#run_classification(BaggingClassifier(n_estimators=10, random_state=0), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "yQ1tHWi7cHhk"
   },
   "outputs": [],
   "source": [
    "params ={'n_estimators':[5,10,30,50,100],'random_state' :[1,10,20]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "FdcQaMmBbz49"
   },
   "outputs": [],
   "source": [
    "bgc = BaggingClassifier()\n",
    "rs_bgc = RandomizedSearchCV(estimator = bgc,\n",
    "                           param_distributions = params,\n",
    "                           cv = 3,random_state = 42, n_jobs = 1, return_train_score= True)\n",
    "#Fitting randomsearch model\n",
    "rs_bgc_results = rs_bgc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Rxkx2XLJcBR-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7156597595128124"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_bgc_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "2yS28yL8b0Dj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_bgc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "47mWl5afb0SN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(n_estimators=100, random_state=10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_bgc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "C63dQwA4b0eL"
   },
   "outputs": [],
   "source": [
    "bgc_clf = rs_bgc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ipTwbVjzb0ot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf', BaggingClassifier(n_estimators=100, random_state=10))])\n",
      "================================================================================\n",
      "Training accuracy: 82.18%\n",
      "Testing accuracy: 73.31%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[994   0   2 ...   2   8   2]\n",
      " [  0  29   0 ...   0   3   0]\n",
      " [  0   0 148 ...   0  13   0]\n",
      " ...\n",
      " [  1   0   0 ...  90   0   0]\n",
      " [  1   0   4 ...   0 565   2]\n",
      " [  1   0   0 ...   0  97 101]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      1182\n",
      "           1       0.74      0.63      0.68        46\n",
      "           2       0.78      0.80      0.79       184\n",
      "           3       0.88      0.94      0.91        48\n",
      "           4       0.67      0.70      0.69       503\n",
      "           5       0.96      0.90      0.93       225\n",
      "           6       0.93      0.91      0.92       184\n",
      "           7       0.93      0.98      0.96        58\n",
      "           8       0.84      0.95      0.89       134\n",
      "           9       0.80      0.97      0.88        37\n",
      "          10       0.99      0.94      0.97       135\n",
      "          11       0.88      0.95      0.92       310\n",
      "          12       0.89      0.85      0.87       313\n",
      "          13       0.98      0.91      0.95        58\n",
      "          14       0.98      1.00      0.99        43\n",
      "          15       0.96      0.98      0.97        46\n",
      "          16       0.89      0.92      0.91        37\n",
      "          17       0.52      0.63      0.57       814\n",
      "          18       0.65      0.72      0.68       245\n",
      "          19       0.90      0.82      0.86        91\n",
      "          20       1.00      0.93      0.96        27\n",
      "          21       0.59      0.62      0.60       107\n",
      "          22       0.96      0.90      0.93       151\n",
      "          23       0.93      0.92      0.92       298\n",
      "          24       0.19      0.10      0.13       131\n",
      "          25       0.60      0.38      0.47       129\n",
      "          26       0.42      0.45      0.43       483\n",
      "          27       0.57      0.65      0.61       138\n",
      "          28       0.96      1.00      0.98        24\n",
      "          29       0.95      0.90      0.93       151\n",
      "          30       0.90      0.99      0.94        67\n",
      "          31       0.98      1.00      0.99        60\n",
      "          32       0.41      0.33      0.37       214\n",
      "          33       0.98      0.87      0.92        46\n",
      "          34       0.88      0.68      0.77        34\n",
      "          35       0.09      0.08      0.08       105\n",
      "          36       0.59      0.40      0.48       127\n",
      "          37       0.74      0.56      0.64       196\n",
      "          38       1.00      0.50      0.67        18\n",
      "          39       0.85      0.97      0.90        29\n",
      "          40       0.97      0.87      0.91       104\n",
      "          41       0.63      0.85      0.73       662\n",
      "          42       0.74      0.40      0.52       250\n",
      "\n",
      "    accuracy                           0.73      8244\n",
      "   macro avg       0.79      0.76      0.77      8244\n",
      "weighted avg       0.74      0.73      0.73      8244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification(bgc_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd3PAGHmrFaj"
   },
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfLNzU90rFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=42)), ('svr', make_pipeline(StandardScaler(with_mean=False), LinearSVC(random_state=42)))]\n",
    "\n",
    "run_classification(StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier()), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCl8T1jNrFaj"
   },
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q_lE-UerFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=42)), ('dtc', DecisionTreeClassifier(random_state=42)), ('lsvc', LinearSVC(random_state=42))]\n",
    "\n",
    "run_classification(VotingClassifier(estimators=estimators, voting='hard'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DYDSEoVrFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=42)), ('dtc', DecisionTreeClassifier(random_state=42)), ('lsvc', SVC(kernel='linear',probability=True))]\n",
    "\n",
    "run_classification(VotingClassifier(estimators=estimators, voting='soft'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVNcUZ1BQWrL"
   },
   "source": [
    "## Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RelfajlQWrL"
   },
   "outputs": [],
   "source": [
    "# Load the augmented data from pickle file \n",
    "with open('/content/Interim_data.pkl','rb') as f:\n",
    "    clean_data_DL = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15XBDLMRQWrL"
   },
   "outputs": [],
   "source": [
    "clean_data_DL.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxgUQxvhQWrL"
   },
   "outputs": [],
   "source": [
    "clean_data_DL['Final_Text'] = clean_data_DL['Final_Text'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzJ4VnECQWrM"
   },
   "outputs": [],
   "source": [
    "clean_data_DL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTiSKPsIr7RX"
   },
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "clean_data_DL['Assignment group LabelEncoded']= label_encoder.fit_transform(clean_data_DL['Assignment group']) \n",
    "  \n",
    "clean_data_DL['Assignment group LabelEncoded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwiIGk4ar7gA"
   },
   "outputs": [],
   "source": [
    "onehot_encoded_dict = dict(zip(clean_data_DL['Assignment group'].unique(), clean_data_DL['Assignment group LabelEncoded'].unique()))\n",
    "len(onehot_encoded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibiTTlGLQWrM"
   },
   "outputs": [],
   "source": [
    "# Splitting Train Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_data_DL['Final_Text'], clean_data_DL['Assignment group LabelEncoded'], test_size=0.3, random_state = 0, stratify=clean_data_DL['Assignment group LabelEncoded'])\n",
    "print('\\033[1mShape of the training set:\\033[0m', X_train.shape, X_test.shape)\n",
    "print('\\033[1mShape of the test set:\\033[0m', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GOVYYV9QWrM"
   },
   "source": [
    "### Create checkpoints function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RG6wVQXQWrN"
   },
   "outputs": [],
   "source": [
    "#Path where you want to save the weights, model and checkpoints\n",
    "model_path = \"Weights/\"\n",
    "%mkdir Weights\n",
    "\n",
    "# Define model callbacks\n",
    "def call_backs(name):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.01, patience=3)\n",
    "    model_checkpoint =  ModelCheckpoint(model_path + name + '_epoch{epoch:02d}_loss{val_loss:.4f}.h5',\n",
    "                                                               monitor='val_loss',\n",
    "                                                               verbose=1,\n",
    "                                                               save_best_only=True,\n",
    "                                                               save_weights_only=False,\n",
    "                                                               mode='min',\n",
    "                                                               period=1)\n",
    "    return [model_checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAC5r5UcQWrN"
   },
   "outputs": [],
   "source": [
    "# Function to build Neural Network\n",
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.3):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdB5_mvzQWrN"
   },
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=2000)\n",
    "Tfidf_vect.fit(clean_data_DL.Final_Text.astype(str))\n",
    "X_train_tfidf = Tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = Tfidf_vect.transform(X_test)\n",
    "\n",
    "# Instantiate the network\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6aC4UqOQWrN"
   },
   "outputs": [],
   "source": [
    "run_classification(model_DNN, X_train_tfidf, X_test_tfidf, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='DNN')\n",
    "\n",
    "'''model_DNN.fit(X_train_tfidf, y_train,\n",
    "                              validation_data=(X_test_tfidf, y_test),\n",
    "                              callbacks=call_backs(\"NN\"),\n",
    "                              epochs=10,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)\n",
    "predicted = model_DNN.predict(X_test_tfidf)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaCQnFBRQWrO"
   },
   "source": [
    "### Extract Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMA3MFYUQWrO"
   },
   "outputs": [],
   "source": [
    "#download the glove embedding zip file from http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
    "from zipfile import ZipFile\n",
    "# Check if it is already extracted else Open the zipped file as readonly\n",
    "if not os.path.isfile('glove.6B/glove.6B.200d.txt'):\n",
    "    #glove_embeddings = 'glove.6B.zip'\n",
    "    glove_embeddings = '/content/drive/MyDrive/Capstone/glove.6B.zip'\n",
    "    with ZipFile(glove_embeddings, 'r') as archive:\n",
    "        archive.extractall('glove.6B')\n",
    "\n",
    "# List the files under extracted folder\n",
    "os.listdir('glove.6B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2Xtecr3QWrO"
   },
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghIAygEfQWrO"
   },
   "outputs": [],
   "source": [
    "#gloveFileName = 'glove.6B/glove.6B.200d.txt'\n",
    "gloveFileName = '/content/glove.6B/glove.6B.200d.txt'\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "EMBEDDING_DIM=200\n",
    "MAX_NB_WORDS=75000\n",
    "\n",
    "# Function to generate Embedding\n",
    "def loadData_Tokenizer(X_train, X_test,filename):\n",
    "    np.random.seed(7)\n",
    "    text = np.concatenate((X_train, X_test), axis=0)\n",
    "    text = np.array(text)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_train = text[0:len(X_train), ]\n",
    "    X_test = text[len(X_train):, ]\n",
    "    embeddings_index = {}\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_train, X_test, word_index,embeddings_index)\n",
    "\n",
    "\n",
    "embedding_matrix = []\n",
    "\n",
    "def buildEmbed_matrices(word_index,embedding_dim):\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
    "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])), \"into shape\",str(len(embedding_vector)),\n",
    "                      \" Please make sure your\"\" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
    "                exit(1)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DljFFfKxQWrO"
   },
   "outputs": [],
   "source": [
    "# Generate Glove embedded datasets\n",
    "X_train_Glove, X_test_Glove, word_index, embeddings_index = loadData_Tokenizer(X_train,X_test,gloveFileName)\n",
    "embedding_matrix = buildEmbed_matrices(word_index,EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URiIMsVEQWrO"
   },
   "outputs": [],
   "source": [
    "def Build_Model_CNN_Text(word_index, embeddings_matrix, nclasses,dropout=0.5):\n",
    "    \"\"\"\n",
    "        def buildModel_CNN(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
    "        word_index in word index ,\n",
    "        embeddings_index is embeddings index, look at data_helper.py\n",
    "        nClasses is number of classes,\n",
    "        MAX_SEQUENCE_LENGTH is maximum lenght of text sequences,\n",
    "        EMBEDDING_DIM is an int value for dimention of word embedding look at data_helper.py\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "    # applying a more complex convolutional approach\n",
    "    convs = []\n",
    "    filter_sizes = []\n",
    "    layer = 5\n",
    "    print(\"Filter  \",layer)\n",
    "    for fl in range(0,layer):\n",
    "        filter_sizes.append((fl+2))\n",
    "    node = 128\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(node, kernel_size=fsz, activation='relu')(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(5)(l_conv)\n",
    "        #l_pool = Dropout(0.25)(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "    l_cov1 = Conv1D(node, 5, activation='relu')(l_merge)\n",
    "    l_cov1 = Dropout(dropout)(l_cov1)\n",
    "    l_batch1 = BatchNormalization()(l_cov1)\n",
    "    l_pool1 = MaxPooling1D(5)(l_batch1)\n",
    "    l_cov2 = Conv1D(node, 5, activation='relu')(l_pool1)\n",
    "    l_cov2 = Dropout(dropout)(l_cov2)\n",
    "    l_batch2 = BatchNormalization()(l_cov2)\n",
    "    l_pool2 = MaxPooling1D(30)(l_batch2)\n",
    "    l_flat = Flatten()(l_pool2)\n",
    "    l_dense = Dense(1024, activation='relu')(l_flat)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "    l_dense = Dense(512, activation='relu')(l_dense)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxdeJLw9QWrP"
   },
   "outputs": [],
   "source": [
    "# Train the network and run classification\n",
    "model_CNN = Build_Model_CNN_Text(word_index,embedding_matrix, 43)\n",
    "run_classification(model_CNN, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMu2ONzLQWrP"
   },
   "source": [
    "## Recurrent Neural Networks (RNN) --> Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grFaHdizQWrP"
   },
   "outputs": [],
   "source": [
    "def Build_Model_RNN_Text(word_index, embeddings_matrix, nclasses,dropout=0.5):\n",
    "    \"\"\"\n",
    "    def buildModel_RNN(word_index, embeddings_matrix, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=100, dropout=0.5):\n",
    "    word_index in word index ,\n",
    "    embeddings_matrix is embeddings_matrix, look at data_helper.py\n",
    "    nClasses is number of classes,\n",
    "    MAX_SEQUENCE_LENGTH is maximum lenght of text sequences\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    hidden_layer = 3\n",
    "    gru_node = 32\n",
    "    \n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True))\n",
    "    print(gru_node)\n",
    "    for i in range(0,hidden_layer):\n",
    "        model.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(GRU(gru_node, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nclasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='sgd',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlNeKO-3QWrP"
   },
   "outputs": [],
   "source": [
    "# Train the network and run classification\n",
    "model_RNN = Build_Model_RNN_Text(word_index,embedding_matrix, 43)\n",
    "run_classification(model_RNN, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='RNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVAZo1u8QWrP"
   },
   "source": [
    "## RNN with LSTM networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtFjAJ4oQWrQ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "#gloveFileName = 'glove.6B/glove.6B.100d.txt'\n",
    "gloveFileName = '/content/glove.6B/glove.6B.200d.txt'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, TimeDistributed, Activation\n",
    "from keras.layers import Flatten, Permute, merge, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, multiply, concatenate, Dropout\n",
    "from keras.layers import GRU, Bidirectional\n",
    "\n",
    "\n",
    "def Build_Model_LTSM_Text(word_index, embeddings_matrix, nclasses):\n",
    "    kernel_size = 2\n",
    "    filters = 256\n",
    "    pool_size = 2\n",
    "    gru_node = 256\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Bidirectional(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    model.add(Bidirectional(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    model.add(Bidirectional(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    model.add(Bidirectional(LSTM(gru_node, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dense(nclasses))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0973kvsQWrQ"
   },
   "outputs": [],
   "source": [
    "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test,gloveFileName)\n",
    "embedding_matrix = buildEmbed_matrices(word_index,EMBEDDING_DIM)\n",
    "\n",
    "model_LTSM = Build_Model_LTSM_Text(word_index,embedding_matrix, 43)\n",
    "run_classification(model_LTSM, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='LSTM')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "25Dec_Ashitha.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
