{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guptapawan227/Capstone_AIML/blob/Ashish/Recreated_16thDec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XycWjq1YtXnI"
   },
   "source": [
    "Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_AZpolni4uT",
    "outputId": "ee082f26-2ad6-461a-996d-0915ab20e679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX79JvNILSQK",
    "outputId": "7e5d948a-9657-4c63-a9ac-68a3b8f461d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.8)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeHuMI62tbyY"
   },
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "01_3Wr6nw-ee"
   },
   "outputs": [],
   "source": [
    "# Using TensorFlow 1.x only in colab as found a issue with 2.3 version used by colab while working with DNN model fit. Did not observe any issue with Tensor flow 2.1 version on local jupyter enviornment.\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GDYfqgy9q1p_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, sys, itertools, re \n",
    "from PIL import Image\n",
    "import warnings, pickle, string\n",
    "from dateutil import parser\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Visualization\n",
    "import cufflinks as cf\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "\n",
    "from ftfy import fix_text, badness\n",
    "\n",
    "# Traditional Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "'''# Sequential Modeling\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, Embedding, LSTM, GRU\n",
    "from keras.layers import BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D\n",
    "from keras.constraints import max_norm, unit_norm\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint'''\n",
    "\n",
    "# Sequential Modeling\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Dense, Embedding, LSTM, GRU, Bidirectional, multiply, Permute, merge\n",
    "from tensorflow.keras.layers import BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D, Activation, Embedding\n",
    "from tensorflow.keras.constraints import max_norm, unit_norm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Tools & Evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
    "from sklearn.metrics import roc_curve, accuracy_score, precision_recall_curve\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjfS1VF6teuM"
   },
   "source": [
    "Reading the data from excel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBwzB1oFYRiQ"
   },
   "source": [
    "## Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n795kT7hYjSo"
   },
   "source": [
    "#### Load the consolidated final translated pickle file which contains the language translations. The Process used for language translation is through google translate function in Google spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LV6wyT6iXXHR"
   },
   "outputs": [],
   "source": [
    "# Load the consolidated final translated pickle file \n",
    "#with open('/content/drive/MyDrive/Capstone/Final_Translated_combined.pkl','rb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/final_translated.pkl','rb') as f:\n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNYuIWcuhqrR"
   },
   "outputs": [],
   "source": [
    "clean_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpDjY6fmrFaW"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt=clean_data['Assignment group'].value_counts()\n",
    "assignment_group_cnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylx7gPuAXXHS"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx66akCuXXHS"
   },
   "outputs": [],
   "source": [
    "#Removing groups with 4 or less records as those groups have been already added to rule matrix and these records are left overs\n",
    "\n",
    "clean_data = clean_data[(clean_data[\"Assignment group\"] != 'GRP_55') & (clean_data[\"Assignment group\"] != 'GRP_66') & (clean_data[\"Assignment group\"] != 'GRP_68') & (clean_data[\"Assignment group\"] != 'GRP_72') & (clean_data[\"Assignment group\"] != 'GRP_57') & (clean_data[\"Assignment group\"] != 'GRP_56') & (clean_data[\"Assignment group\"] != 'GRP_32')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTZyoprphuPp"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0otMnQVXXHS"
   },
   "outputs": [],
   "source": [
    "#Install NLPAug Package\n",
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxWgb3dVXXHT"
   },
   "outputs": [],
   "source": [
    "#Install dependencies for nlpaug\n",
    "!pip install torch>=1.6.0 transformers>=4.0.0\n",
    "!pip install nltk>=3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6rBnRM6XXHT"
   },
   "outputs": [],
   "source": [
    "#We will use Word Augmentation methods. nlpaug supports character, word and sentence level augmentation methods\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jwQU3x-XXHT"
   },
   "outputs": [],
   "source": [
    "#Word embedding augmentation method\n",
    "aug1 = naw.WordEmbsAug(model_type='glove', model_path='glove.6B/glove.6B.50d.txt', action=\"substitute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3x_3u5xXXHT"
   },
   "outputs": [],
   "source": [
    "aug2 = naw.WordEmbsAug(model_type='glove', model_path='glove.6B/glove.6B.50d.txt', action=\"insert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XuO6nsrXXHT"
   },
   "outputs": [],
   "source": [
    "#Contextual Word augmentation method\n",
    "aug3 = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"substitute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwQ_QF6xXXHU"
   },
   "outputs": [],
   "source": [
    "aug4 = naw.ContextualWordEmbsAug(model_path='roberta-base', action=\"substitute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BCItTbhXXHU"
   },
   "outputs": [],
   "source": [
    "#Synonym Augmentation method using PPDB models downloaded from http://paraphrase.org/#/download\n",
    "aug5 = naw.SynonymAug(aug_src='ppdb', model_path='ppdb-2.0-s-all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_qdWy1yBsjO"
   },
   "outputs": [],
   "source": [
    "#!pip3 install nltk\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Erip7CBw7P_P"
   },
   "outputs": [],
   "source": [
    "#Create a new dataframe with records not in GRP_0\n",
    "zero_dataframe = clean_data[clean_data[\"Assignment group\"] == 'GRP_0']\n",
    "new_dataframe = clean_data[clean_data[\"Assignment group\"] != 'GRP_0']\n",
    "zero_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0T0xGDHXXHV"
   },
   "outputs": [],
   "source": [
    "#Create dataframe copies for different augmentation methods\n",
    "new_dataframe2 = new_dataframe.copy()\n",
    "new_dataframe3 = new_dataframe.copy()\n",
    "new_dataframe4 = new_dataframe.copy()\n",
    "new_dataframe5 = new_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB8ELEaPRyuQ"
   },
   "outputs": [],
   "source": [
    "new_dataframe.shape, zero_dataframe.shape, new_dataframe2.shape, new_dataframe3.shape, new_dataframe4.shape, new_dataframe5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sejv9y4eXXHV"
   },
   "outputs": [],
   "source": [
    "new_dataframe[\"Augmented_data\"] = new_dataframe.apply(lambda x: aug1.augment(x['Translated_Text']),axis=1)\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThnwxmfATCun"
   },
   "outputs": [],
   "source": [
    "s = new_dataframe.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug = new_dataframe.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated_Text'],axis=1).join(s)\n",
    "new_dataframe_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tx85XamZXXHW"
   },
   "outputs": [],
   "source": [
    "new_dataframe2[\"Augmented_data\"] = new_dataframe2.apply(lambda x: aug2.augment(x['Translated_Text']),axis=1)\n",
    "new_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLgWdXXVXXHW"
   },
   "outputs": [],
   "source": [
    "s = new_dataframe2.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug2 = new_dataframe2.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated_Text'],axis=1).join(s)\n",
    "new_dataframe_aug2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAE3oGEfXXHW"
   },
   "outputs": [],
   "source": [
    "new_dataframe3[\"Augmented_data\"] = new_dataframe3.apply(lambda x: aug3.augment(x['Translated_Text']),axis=1)\n",
    "new_dataframe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4--py3LmXXHX"
   },
   "outputs": [],
   "source": [
    "s = new_dataframe3.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug3 = new_dataframe3.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated_Text'],axis=1).join(s)\n",
    "new_dataframe_aug3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDyITkYgXXHX"
   },
   "outputs": [],
   "source": [
    "new_dataframe4[\"Augmented_data\"] = new_dataframe4.apply(lambda x: aug4.augment(x['Translated_Text']),axis=1)\n",
    "new_dataframe4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXl02NcsXXHX"
   },
   "outputs": [],
   "source": [
    "s = new_dataframe4.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug4 = new_dataframe4.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated_Text'],axis=1).join(s)\n",
    "new_dataframe_aug4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUpmrNswXXHX"
   },
   "outputs": [],
   "source": [
    "new_dataframe5[\"Augmented_data\"] = new_dataframe5.apply(lambda x: aug5.augment(x['Translated_Text']),axis=1)\n",
    "new_dataframe5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUYBFgeNXXHX"
   },
   "outputs": [],
   "source": [
    "s = new_dataframe5.apply(lambda x: pd.Series(x['Augmented_data']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Final_Text'\n",
    "new_dataframe_aug5 = new_dataframe5.drop(['New Description','Augmented_data', 'Clean_Description', 'Translated_Text'],axis=1).join(s)\n",
    "new_dataframe_aug5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcQ3e0XSBsjT"
   },
   "outputs": [],
   "source": [
    "zero_dataframe = zero_dataframe.rename(columns={\"Translated_Text\": \"Final_Text\"})\n",
    "zero_dataframe = zero_dataframe.drop(['New Description', 'Clean_Description'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad3_dUcRXXHY"
   },
   "outputs": [],
   "source": [
    "zero_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDvBTh_3XXHY"
   },
   "outputs": [],
   "source": [
    "#Adding Original data (without Augmentation)\n",
    "new_dataframe6 = clean_data[clean_data[\"Assignment group\"] != 'GRP_0']\n",
    "new_dataframe6 = new_dataframe6.rename(columns={\"Translated_Text\": \"Final_Text\"})\n",
    "new_dataframe6 = new_dataframe6.drop(['New Description', 'Clean_Description'], axis = 1)\n",
    "new_dataframe6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKAQ_5z9XXHY"
   },
   "outputs": [],
   "source": [
    "dataframes=[new_dataframe_aug, new_dataframe_aug2, new_dataframe_aug3, new_dataframe_aug4, new_dataframe_aug5, zero_dataframe, new_dataframe6]\n",
    "clean_data_result= pd.concat(dataframes)\n",
    "clean_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyVF75jXXXHZ"
   },
   "outputs": [],
   "source": [
    "#Remove duplicate rows after augmentation\n",
    "clean_data_result = clean_data_result.drop_duplicates(subset='Final_Text', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFKf35cRQWq9"
   },
   "outputs": [],
   "source": [
    "# Serialize the Augmented dataset for later use\n",
    "clean_data_result.to_csv('Interim_data.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Interim_data.pkl','wb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/Interim_data.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_result, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-l1WsyBqXXHa"
   },
   "outputs": [],
   "source": [
    "# Load the consolidated final translated pickle file \n",
    "#with open('/content/drive/MyDrive/Capstone/Interim_data.pkl','rb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/Interim_data.pkl','rb') as f:\n",
    "    clean_data_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcVQhHCPXXHa"
   },
   "outputs": [],
   "source": [
    "clean_data_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzxDdWyMBsjT"
   },
   "source": [
    "## Stop words removal and Lemmatise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSfE-xBvrFaY"
   },
   "outputs": [],
   "source": [
    "clean_data_result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45rNIDGvBsjU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "processed_all_documents = list()\n",
    "\n",
    "for desc in clean_data_result['Final_Text']:\n",
    "    word_tokens = word_tokenize(desc) \n",
    "    \n",
    "    filtered_sentence = [] \n",
    "\n",
    "    # Removing Stopwords\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    words = ' '.join(filtered_sentence)\n",
    "    processed_all_documents.append(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dh0hMMrrFaZ"
   },
   "outputs": [],
   "source": [
    "clean_data_result['Final_Text'] = processed_all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xn4waA6MBsjU"
   },
   "outputs": [],
   "source": [
    "clean_data_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ7s9d10EWG8"
   },
   "outputs": [],
   "source": [
    "clean_data_result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8YU9JQqEWG8"
   },
   "outputs": [],
   "source": [
    "clean_data_result.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWJN-ekLBsjU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lemmatisation using spacy library\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeoMfBEBBsjU"
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HWRcbMrrOgn"
   },
   "outputs": [],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAGj1FplBsjV"
   },
   "outputs": [],
   "source": [
    "# Need to run \"python -m spacy download en\" in anaconda prompt to avoid 'en' not found issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Pxl8SyyBsjV"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "clean_data_result['Final_Text'] = clean_data_result['Final_Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0YLyD-iBsjV"
   },
   "outputs": [],
   "source": [
    "clean_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uW7ME5zaXXHd"
   },
   "outputs": [],
   "source": [
    "clean_data_result1 = clean_data_result[clean_data_result['Final_Text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pII3nsHPXXHd"
   },
   "outputs": [],
   "source": [
    "clean_data_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOUtnN-lXXHd"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt=clean_data_result1['Assignment group'].value_counts()\n",
    "assignment_group_cnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsQYhBTIXXHe"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt.tail(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yJf4QCZaoah"
   },
   "outputs": [],
   "source": [
    "# Final data pkl file after augmentation, stopwords removal and lemmatisation\n",
    "clean_data_result1.to_csv('Final_data.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Final_data.pkl','wb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/Final_data.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_result1, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-zXZRYDaoah"
   },
   "outputs": [],
   "source": [
    "# Load the translated pickle file \n",
    "with open('/content/drive/MyDrive/Capstone/Final_data.pkl','rb') as f:\n",
    "#with open('/content/drive/MyDrive/Capstone/Final_data.pkl','rb') as f:\n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGOLdr4KbRq-"
   },
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFFmdwYobRq-"
   },
   "source": [
    "## Manual inspection showed that groups having Monitoring tool emails and Job scheduler errors are dropping the accuracy as they cant be used for machine learning as no patterns. Moving them into 1 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWMWMtCCbRq-"
   },
   "outputs": [],
   "source": [
    "#Moving all the records coming from monitoring tool/job scheduler to one group\n",
    "\n",
    "clean_data.loc[(clean_data['Final_Text'].astype(str).str.contains('scheduler')), 'Assignment group'] = \"GRP_MonitoringTool\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYbCP36obRq_"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt=clean_data['Assignment group'].value_counts()\n",
    "assignment_group_cnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROYXT6-abRq_"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt = clean_data['Assignment group'].value_counts().rename_axis('Grp_name').reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1VrxHr1bRq_"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvD4fjkbbRq_"
   },
   "outputs": [],
   "source": [
    "# Saving pkl file after creating new target group for job_scheduler emails\n",
    "clean_data.to_csv('Final_data1.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Final_data.pkl','wb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/Final_data1.pkl','wb') as f:\n",
    "    pickle.dump(clean_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGabVgP0bRq_"
   },
   "source": [
    "## Resampling the groups having less than 500 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31QJOD8abRq_"
   },
   "outputs": [],
   "source": [
    "#Sory for the messy code, didnt have patience to write a lambda function. Splitting dataframes with < 500 records for resampling\n",
    "temp_dataframe = clean_data[(clean_data[\"Assignment group\"] == 'GRP_43') | (clean_data[\"Assignment group\"] == 'GRP_46') | (clean_data[\"Assignment group\"] == 'GRP_59') | (clean_data[\"Assignment group\"] == 'GRP_49') | (clean_data[\"Assignment group\"] == 'GRP_60') | (clean_data[\"Assignment group\"] == 'GRP_51') | (clean_data[\"Assignment group\"] == 'GRP_52') | (clean_data[\"Assignment group\"] == 'GRP_65') | (clean_data[\"Assignment group\"] == 'GRP_53') | (clean_data[\"Assignment group\"] == 'GRP_39') | (clean_data[\"Assignment group\"] == 'GRP_36') | (clean_data[\"Assignment group\"] == 'GRP_50') | (clean_data[\"Assignment group\"] == 'GRP_44') | (clean_data[\"Assignment group\"] == 'GRP_47') | (clean_data[\"Assignment group\"] == 'GRP_37') | (clean_data[\"Assignment group\"] == 'GRP_27') | (clean_data[\"Assignment group\"] == 'GRP_5') | (clean_data[\"Assignment group\"] == 'GRP_1') | (clean_data[\"Assignment group\"] == 'GRP_62') | (clean_data[\"Assignment group\"] == 'GRP_23') | (clean_data[\"Assignment group\"] == 'GRP_17') | (clean_data[\"Assignment group\"] == 'GRP_48') | (clean_data[\"Assignment group\"] == 'GRP_45') | (clean_data[\"Assignment group\"] == 'GRP_21') | (clean_data[\"Assignment group\"] == 'GRP_11') | (clean_data[\"Assignment group\"] == 'GRP_22') | (clean_data[\"Assignment group\"] == 'GRP_20') | (clean_data[\"Assignment group\"] == 'GRP_42') | (clean_data[\"Assignment group\"] == 'GRP_30') | (clean_data[\"Assignment group\"] == 'GRP_15') | (clean_data[\"Assignment group\"] == 'GRP_41') | (clean_data[\"Assignment group\"] == 'GRP_28') | (clean_data[\"Assignment group\"] == 'GRP_40') | (clean_data[\"Assignment group\"] == 'GRP_26') | (clean_data[\"Assignment group\"] == 'GRP_34') | (clean_data[\"Assignment group\"] == 'GRP_6') | (clean_data[\"Assignment group\"] == 'GRP_7') | (clean_data[\"Assignment group\"] == 'GRP_31') | (clean_data[\"Assignment group\"] == 'GRP_9') | (clean_data[\"Assignment group\"] == 'GRP_10')]\n",
    "temp_dataframe2 = clean_data[(clean_data[\"Assignment group\"] != 'GRP_43') & (clean_data[\"Assignment group\"] != 'GRP_46') & (clean_data[\"Assignment group\"] != 'GRP_59') & (clean_data[\"Assignment group\"] != 'GRP_49') & (clean_data[\"Assignment group\"] != 'GRP_60') & (clean_data[\"Assignment group\"] != 'GRP_51') & (clean_data[\"Assignment group\"] != 'GRP_52') & (clean_data[\"Assignment group\"] != 'GRP_65') & (clean_data[\"Assignment group\"] != 'GRP_53') & (clean_data[\"Assignment group\"] != 'GRP_39') & (clean_data[\"Assignment group\"] != 'GRP_36') & (clean_data[\"Assignment group\"] != 'GRP_50') & (clean_data[\"Assignment group\"] != 'GRP_44') & (clean_data[\"Assignment group\"] != 'GRP_47') & (clean_data[\"Assignment group\"] != 'GRP_37') & (clean_data[\"Assignment group\"] != 'GRP_27') & (clean_data[\"Assignment group\"] != 'GRP_5') & (clean_data[\"Assignment group\"] != 'GRP_1') & (clean_data[\"Assignment group\"] != 'GRP_62') & (clean_data[\"Assignment group\"] != 'GRP_23') & (clean_data[\"Assignment group\"] != 'GRP_17') & (clean_data[\"Assignment group\"] != 'GRP_48') & (clean_data[\"Assignment group\"] != 'GRP_45') & (clean_data[\"Assignment group\"] != 'GRP_21') & (clean_data[\"Assignment group\"] != 'GRP_11') & (clean_data[\"Assignment group\"] != 'GRP_22') & (clean_data[\"Assignment group\"] != 'GRP_20') & (clean_data[\"Assignment group\"] != 'GRP_42') & (clean_data[\"Assignment group\"] != 'GRP_30') & (clean_data[\"Assignment group\"] != 'GRP_15') & (clean_data[\"Assignment group\"] != 'GRP_41') & (clean_data[\"Assignment group\"] != 'GRP_28') & (clean_data[\"Assignment group\"] != 'GRP_40') & (clean_data[\"Assignment group\"] != 'GRP_26') & (clean_data[\"Assignment group\"] != 'GRP_34') & (clean_data[\"Assignment group\"] != 'GRP_6') & (clean_data[\"Assignment group\"] != 'GRP_7') & (clean_data[\"Assignment group\"] != 'GRP_31') & (clean_data[\"Assignment group\"] != 'GRP_9') & (clean_data[\"Assignment group\"] != 'GRP_10')]\n",
    "temp_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNRUtUf_bRrA"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt2 = temp_dataframe2['Assignment group'].value_counts().rename_axis('Grp_name').reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRGqPDTjbRrA"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-ca0C6_bRrA"
   },
   "outputs": [],
   "source": [
    "#resampling all groups having less than 500 records\n",
    "from sklearn.utils import resample\n",
    "clean_data_resampled = temp_dataframe[0:0]\n",
    "for grp in temp_dataframe['Assignment group'].unique():\n",
    "    temp_dataframe1 = temp_dataframe.apply(lambda x : True\n",
    "            if str(temp_dataframe['Assignment group']) == grp else False, axis = 1)\n",
    "    num_rows = len(temp_dataframe1[temp_dataframe1 == True].index) \n",
    "    if(num_rows < 500):\n",
    "            temp_dataframeGrpDF = temp_dataframe[temp_dataframe['Assignment group'] == grp]\n",
    "            resampled = resample(temp_dataframeGrpDF, replace=True, n_samples=500, random_state=123)\n",
    "            clean_data_resampled = clean_data_resampled.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XKL4wdTbRrA"
   },
   "outputs": [],
   "source": [
    "clean_data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNHqoj89bRrA"
   },
   "outputs": [],
   "source": [
    "#Concat dataframes post resampling\n",
    "dataframes=[clean_data_resampled, temp_dataframe2]\n",
    "clean_data_resampled= pd.concat(dataframes)\n",
    "clean_data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RIIM4lBbRrA"
   },
   "outputs": [],
   "source": [
    "assignment_group_cnt3 = clean_data_resampled['Assignment group'].value_counts().rename_axis('Grp_name').reset_index(name='counts')\n",
    "assignment_group_cnt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnGIPaLmbRrB"
   },
   "outputs": [],
   "source": [
    "# Saving pkl file after resampling\n",
    "clean_data_resampled.to_csv('Final_data_resampled.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Final_data.pkl','wb') as f:\n",
    "with open('Final_data_resampled.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_resampled, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from here to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the translated pickle file. Load from here to save time. \n",
    "with open('/content/drive/MyDrive/Capstone/Final_data_resampled.pkl','rb') as f:\n",
    "#with open('/content/drive/MyDrive/Capstone/Final_data.pkl','rb') as f:\n",
    "    clean_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhCUgD6_Bsjn"
   },
   "source": [
    "## Prepping Dataframe for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ijBA6KgW13C"
   },
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRguKfOkEWHJ"
   },
   "outputs": [],
   "source": [
    "'''# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "clean_data['Assignment group LabelEncoded']= label_encoder.fit_transform(clean_data['Assignment group']) \n",
    "  \n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "clean_data['Assignment group LabelEncoded'] = clean_data['Assignment group LabelEncoded'].values.reshape(len(clean_data['Assignment group LabelEncoded']), 1)\n",
    "clean_data['Assignment group OneHotEncoded'] = onehot_encoder.fit_transform(clean_data[['Assignment group LabelEncoded']])\n",
    "clean_data['Assignment group OneHotEncoded']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH6wh6DfXXHf"
   },
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "clean_data['Assignment group LabelEncoded']= label_encoder.fit_transform(clean_data['Assignment group']) \n",
    "\n",
    "target_strings = label_encoder.inverse_transform(clean_data['Assignment group LabelEncoded'])\n",
    "target_strings_list = np.unique(target_strings).tolist()\n",
    "clean_data['Assignment group LabelEncoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnxKQFCyXXHg"
   },
   "outputs": [],
   "source": [
    "'''# Create a target categorical column\n",
    "clean_data['Assignment group LabelEncoded'] = clean_data['Assignment group'].astype('category').cat.codes\n",
    "clean_data.info()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv0szmBMXXHg"
   },
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXk7kd5KXXHg"
   },
   "outputs": [],
   "source": [
    "clean_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jsBDjGIBsjn"
   },
   "outputs": [],
   "source": [
    "label_encoded_dict = dict(zip(clean_data['Assignment group'].unique(), clean_data['Assignment group LabelEncoded'].unique()))\n",
    "label_encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaaV3zyqBsjo"
   },
   "outputs": [],
   "source": [
    "# Splitting Train Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "#Y = np.array(clean_data['Assignment group OneHotEncoded'])\n",
    "\n",
    "X_train, X_test, y_train1, y_test1 = train_test_split(clean_data['Final_Text'], clean_data['Assignment group LabelEncoded'], test_size=0.3, random_state = 0, stratify=clean_data['Assignment group LabelEncoded'])\n",
    "print('\\033[1mShape of the training set:\\033[0m', X_train.shape, X_test.shape)\n",
    "print('\\033[1mShape of the test set:\\033[0m', y_train1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdB5_mvzQWrN"
   },
   "outputs": [],
   "source": [
    "#Using first method of TFIDF vectors feature extraction\n",
    "Tfidf_vect = TfidfVectorizer(max_features=2500)\n",
    "Tfidf_vect.fit(clean_data.Final_Text.astype(str))\n",
    "X_train_tfidf = Tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3UGzor_Bsjo"
   },
   "outputs": [],
   "source": [
    "#using second method of count vectorizer for features extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CV = CountVectorizer(max_features=2500)\n",
    "\n",
    "X_BoW = CV.fit_transform(clean_data['Final_Text']).toarray()\n",
    "y = clean_data['Assignment group LabelEncoded']\n",
    "\n",
    "print(\"Shape of Input Feature :\",np.shape(X_BoW))\n",
    "print(\"Shape of Target Feature :\",np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ7KxHUoXXHh"
   },
   "outputs": [],
   "source": [
    "# Splitting Train Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_BoW, y, test_size=0.3, random_state = 0, stratify=y)\n",
    "print('\\033[1mShape of the training set:\\033[0m', X_train.shape, X_test.shape)\n",
    "print('\\033[1mShape of the test set:\\033[0m', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "EIni9BjpBsjo"
   },
   "outputs": [],
   "source": [
    "def run_classification(estimator, X_train, X_test, y_train, y_test, arch_name=None, pipelineRequired=True, isDeepModel=False):\n",
    "    # train the model\n",
    "    clf = estimator\n",
    "\n",
    "    if pipelineRequired :\n",
    "        clf = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                     ('clf', estimator),\n",
    "                     ])\n",
    "      \n",
    "    if isDeepModel :\n",
    "        model_history = clf.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=25, batch_size=128,verbose=1,callbacks=call_backs(arch_name))\n",
    "        # predict from the clasiffier\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "    else :\n",
    "        clf.fit(X_train, y_train)\n",
    "        # predict from the clasiffier\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "    \n",
    "    print('Estimator:', clf)\n",
    "    print('='*80)\n",
    "    print('Training accuracy: %.2f%%' % (accuracy_score(y_train,y_train_pred) * 100))\n",
    "    print('Testing accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "    print('='*80)\n",
    "    print('Confusion matrix:\\n %s' % (confusion_matrix(y_test, y_pred)))\n",
    "    print('='*80)\n",
    "    print('Classification report:\\n %s' % (classification_report(y_test, y_pred, target_names=target_strings_list)))\n",
    "\n",
    "    \n",
    "    if isDeepModel :\n",
    "      plt.plot(model_history.history['acc'])\n",
    "      plt.plot(model_history.history['val_acc'])\n",
    "      plt.title(arch_name+' model accuracy')\n",
    "      plt.ylabel('accuracy')\n",
    "      plt.xlabel('epoch')\n",
    "      plt.legend(['train','test'], loc='upper left')\n",
    "      plt.show()\n",
    "\n",
    "      plt.plot(model_history.history['loss'])\n",
    "      plt.plot(model_history.history['val_loss'])\n",
    "      plt.title(arch_name+' model loss')\n",
    "      plt.ylabel('loss')\n",
    "      plt.xlabel('epoch')\n",
    "      plt.legend(['train','test'], loc='upper left')\n",
    "      plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxlH4wqyBsjo"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_RXTWZfBsjp"
   },
   "outputs": [],
   "source": [
    "run_classification(LogisticRegression(C=5, penalty='l2', solver='liblinear'), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qOlfdxAXXHi"
   },
   "outputs": [],
   "source": [
    "run_classification(LogisticRegression(C=5, penalty='l2', solver='liblinear'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7r6p2SGBsjp"
   },
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hlgbYXyBsjp"
   },
   "outputs": [],
   "source": [
    "run_classification(MultinomialNB(alpha=0, class_prior=None, fit_prior='True'), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-paAhElBXXHj"
   },
   "outputs": [],
   "source": [
    "run_classification(MultinomialNB(alpha=0, class_prior=None, fit_prior='True'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs5ztA2kBsjp"
   },
   "source": [
    "## K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4qwMKt7Bsjq"
   },
   "outputs": [],
   "source": [
    "run_classification(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
    "                     weights='distance'), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWZj6E-_XXHj"
   },
   "outputs": [],
   "source": [
    "run_classification(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
    "                     weights='distance'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDMha2lxBsjq"
   },
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBc7yY11Bsjq"
   },
   "outputs": [],
   "source": [
    "run_classification(LinearSVC(C=1), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxnImzbCXXHk"
   },
   "outputs": [],
   "source": [
    "run_classification(LinearSVC(C=1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDPisp5SBsjq"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyvv2qn5Bsjq"
   },
   "outputs": [],
   "source": [
    "run_classification(DecisionTreeClassifier(criterion='gini', min_samples_leaf=2), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPVTeCZhXXHk"
   },
   "outputs": [],
   "source": [
    "run_classification(DecisionTreeClassifier(criterion='gini', min_samples_leaf=2), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpJIipnsBsjr"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b28KjuoBsjr"
   },
   "outputs": [],
   "source": [
    "run_classification(RandomForestClassifier(criterion= 'entropy', n_estimators=100, random_state=0), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Abe6g29eXXHl"
   },
   "outputs": [],
   "source": [
    "run_classification(RandomForestClassifier(criterion= 'entropy', n_estimators=100, random_state=0), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOuKESHfrFai"
   },
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJr4CJMBBsjr"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "run_classification(GradientBoostingClassifier(max_depth=15, n_estimators=50, random_state=42), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_RaL_roXXHm"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "run_classification(GradientBoostingClassifier(max_depth=15, n_estimators=50, random_state=42), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-lWxfbVrFai"
   },
   "source": [
    "## XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIYQ2WZJrFai"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8q7-fcTurFai"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "run_classification(XGBClassifier(n_estimators=50, max_depth=15), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8q7-fcTurFai"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "run_classification(XGBClassifier(n_estimators=50, max_depth=15), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MizYVnZrFai"
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPuCWrZGrFai"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "run_classification(BaggingClassifier(n_estimators=100, random_state=10), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPuCWrZGrFai"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "run_classification(BaggingClassifier(n_estimators=100, random_state=10), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd3PAGHmrFaj"
   },
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfLNzU90rFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=42)), ('svr', make_pipeline(StandardScaler(with_mean=False), LinearSVC(random_state=42)))]\n",
    "\n",
    "run_classification(StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier()), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfLNzU90rFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=42)), ('svr', make_pipeline(StandardScaler(with_mean=False), LinearSVC(random_state=42)))]\n",
    "\n",
    "run_classification(StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier()), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCl8T1jNrFaj"
   },
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q_lE-UerFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(criterion= 'entropy', n_estimators=100, random_state=42)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
    "                     weights='distance')), ('bg', BaggingClassifier(n_estimators=100, random_state=42)), ('lsvc', LinearSVC(C=1, random_state=42))]\n",
    "\n",
    "run_classification(VotingClassifier(estimators=estimators, voting='hard'), X_train_tfidf, X_test_tfidf, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q_lE-UerFaj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(criterion= 'entropy', n_estimators=100, random_state=42)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
    "                     weights='distance')), ('bg', BaggingClassifier(n_estimators=100, random_state=42)), ('lsvc', LinearSVC(C=1, random_state=42))]\n",
    "\n",
    "run_classification(VotingClassifier(estimators=estimators, voting='hard'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVNcUZ1BQWrL"
   },
   "source": [
    "## Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4RelfajlQWrL"
   },
   "outputs": [],
   "source": [
    "# Load the augmented data from pickle file \n",
    "with open('/content/drive/MyDrive/Capstone/Interim_data.pkl','rb') as f:\n",
    "#with open('Interim_data.pkl','rb') as f:\n",
    "    clean_data_DL = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IVDsnNX4bRrI"
   },
   "outputs": [],
   "source": [
    "clean_data_DL.loc[(clean_data_DL['Final_Text'].astype(str).str.contains('scheduler')), 'Assignment group'] = \"GRP_MonitoringTool\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "RY0ZXOB4bRrI",
    "outputId": "387498b7-080e-49f9-bffd-b435488a28b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sigfdwcj reofwzlm</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>en</td>\n",
       "      <td>though undocking interface, screen will not sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kxsceyzo naokumlb</td>\n",
       "      <td>GRP_4</td>\n",
       "      <td>en</td>\n",
       "      <td>gentles, have two devices that are trying to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bpctwhsn kzqsbmtp</td>\n",
       "      <td>GRP_MonitoringTool</td>\n",
       "      <td>en</td>\n",
       "      <td>job Job_ had in job_scheduler last: needs Job_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bpctwhsn kzqsbmtp</td>\n",
       "      <td>GRP_MonitoringTool</td>\n",
       "      <td>en</td>\n",
       "      <td>getting mm_zscr_dly_merktc failed in job_sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>bpctwhsn kzqsbmtp</td>\n",
       "      <td>GRP_MonitoringTool</td>\n",
       "      <td>en</td>\n",
       "      <td>job mm_zscr_dly_merktc when and job_scheduler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>hugcadrn ixhlwdgt</td>\n",
       "      <td>GRP_2</td>\n",
       "      <td>en</td>\n",
       "      <td>please remove user hugcadrn ixhlwdgt (ralfteim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>pvbomqht smfkuhwi</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>en</td>\n",
       "      <td>pc received multiple windows security updates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>mpihysnw wrctgoan</td>\n",
       "      <td>GRP_29</td>\n",
       "      <td>en</td>\n",
       "      <td>please contact ed pasgryowski (pasgryo) about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>cpmaidhj elbaqmtp</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>en</td>\n",
       "      <td>tablet needs reimaged due to multiple issues w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>avglmrts vhqmtiua</td>\n",
       "      <td>GRP_29</td>\n",
       "      <td>en</td>\n",
       "      <td>good afternoon, am not receiving the emails th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Caller  ...                                         Final_Text\n",
       "17    sigfdwcj reofwzlm  ...  though undocking interface, screen will not sa...\n",
       "31    kxsceyzo naokumlb  ...  gentles, have two devices that are trying to s...\n",
       "46    bpctwhsn kzqsbmtp  ...  job Job_ had in job_scheduler last: needs Job_...\n",
       "49    bpctwhsn kzqsbmtp  ...  getting mm_zscr_dly_merktc failed in job_sched...\n",
       "58    bpctwhsn kzqsbmtp  ...  job mm_zscr_dly_merktc when and job_scheduler ...\n",
       "...                 ...  ...                                                ...\n",
       "8183  hugcadrn ixhlwdgt  ...  please remove user hugcadrn ixhlwdgt (ralfteim...\n",
       "8186  pvbomqht smfkuhwi  ...  pc received multiple windows security updates ...\n",
       "8189  mpihysnw wrctgoan  ...  please contact ed pasgryowski (pasgryo) about ...\n",
       "8193  cpmaidhj elbaqmtp  ...  tablet needs reimaged due to multiple issues w...\n",
       "8194  avglmrts vhqmtiua  ...  good afternoon, am not receiving the emails th...\n",
       "\n",
       "[21252 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dataframe3 = clean_data_DL[(clean_data_DL[\"Assignment group\"] == 'GRP_43') | (clean_data_DL[\"Assignment group\"] == 'GRP_46') | (clean_data_DL[\"Assignment group\"] == 'GRP_59') | (clean_data_DL[\"Assignment group\"] == 'GRP_49') | (clean_data_DL[\"Assignment group\"] == 'GRP_60') | (clean_data_DL[\"Assignment group\"] == 'GRP_51') | (clean_data_DL[\"Assignment group\"] == 'GRP_52') | (clean_data_DL[\"Assignment group\"] == 'GRP_65') | (clean_data_DL[\"Assignment group\"] == 'GRP_53') | (clean_data_DL[\"Assignment group\"] == 'GRP_39') | (clean_data_DL[\"Assignment group\"] == 'GRP_36') | (clean_data_DL[\"Assignment group\"] == 'GRP_50') | (clean_data_DL[\"Assignment group\"] == 'GRP_44') | (clean_data_DL[\"Assignment group\"] == 'GRP_47') | (clean_data_DL[\"Assignment group\"] == 'GRP_37') | (clean_data_DL[\"Assignment group\"] == 'GRP_27') | (clean_data_DL[\"Assignment group\"] == 'GRP_5') | (clean_data_DL[\"Assignment group\"] == 'GRP_1') | (clean_data_DL[\"Assignment group\"] == 'GRP_62') | (clean_data_DL[\"Assignment group\"] == 'GRP_23') | (clean_data_DL[\"Assignment group\"] == 'GRP_17') | (clean_data_DL[\"Assignment group\"] == 'GRP_48') | (clean_data_DL[\"Assignment group\"] == 'GRP_45') | (clean_data_DL[\"Assignment group\"] == 'GRP_21') | (clean_data_DL[\"Assignment group\"] == 'GRP_11') | (clean_data_DL[\"Assignment group\"] == 'GRP_22') | (clean_data_DL[\"Assignment group\"] == 'GRP_20') | (clean_data_DL[\"Assignment group\"] == 'GRP_42') | (clean_data_DL[\"Assignment group\"] == 'GRP_30') | (clean_data_DL[\"Assignment group\"] == 'GRP_15') | (clean_data_DL[\"Assignment group\"] == 'GRP_41') | (clean_data_DL[\"Assignment group\"] == 'GRP_28') | (clean_data_DL[\"Assignment group\"] == 'GRP_40') | (clean_data_DL[\"Assignment group\"] == 'GRP_26') | (clean_data_DL[\"Assignment group\"] == 'GRP_34') | (clean_data_DL[\"Assignment group\"] == 'GRP_6') | (clean_data_DL[\"Assignment group\"] == 'GRP_7') | (clean_data_DL[\"Assignment group\"] == 'GRP_31') | (clean_data_DL[\"Assignment group\"] == 'GRP_9') | (clean_data_DL[\"Assignment group\"] == 'GRP_10')]\n",
    "temp_dataframe4 = clean_data_DL[(clean_data_DL[\"Assignment group\"] != 'GRP_43') & (clean_data_DL[\"Assignment group\"] != 'GRP_46') & (clean_data_DL[\"Assignment group\"] != 'GRP_59') & (clean_data_DL[\"Assignment group\"] != 'GRP_49') & (clean_data_DL[\"Assignment group\"] != 'GRP_60') & (clean_data_DL[\"Assignment group\"] != 'GRP_51') & (clean_data_DL[\"Assignment group\"] != 'GRP_52') & (clean_data_DL[\"Assignment group\"] != 'GRP_65') & (clean_data_DL[\"Assignment group\"] != 'GRP_53') & (clean_data_DL[\"Assignment group\"] != 'GRP_39') & (clean_data_DL[\"Assignment group\"] != 'GRP_36') & (clean_data_DL[\"Assignment group\"] != 'GRP_50') & (clean_data_DL[\"Assignment group\"] != 'GRP_44') & (clean_data_DL[\"Assignment group\"] != 'GRP_47') & (clean_data_DL[\"Assignment group\"] != 'GRP_37') & (clean_data_DL[\"Assignment group\"] != 'GRP_27') & (clean_data_DL[\"Assignment group\"] != 'GRP_5') & (clean_data_DL[\"Assignment group\"] != 'GRP_1') & (clean_data_DL[\"Assignment group\"] != 'GRP_62') & (clean_data_DL[\"Assignment group\"] != 'GRP_23') & (clean_data_DL[\"Assignment group\"] != 'GRP_17') & (clean_data_DL[\"Assignment group\"] != 'GRP_48') & (clean_data_DL[\"Assignment group\"] != 'GRP_45') & (clean_data_DL[\"Assignment group\"] != 'GRP_21') & (clean_data_DL[\"Assignment group\"] != 'GRP_11') & (clean_data_DL[\"Assignment group\"] != 'GRP_22') & (clean_data_DL[\"Assignment group\"] != 'GRP_20') & (clean_data_DL[\"Assignment group\"] != 'GRP_42') & (clean_data_DL[\"Assignment group\"] != 'GRP_30') & (clean_data_DL[\"Assignment group\"] != 'GRP_15') & (clean_data_DL[\"Assignment group\"] != 'GRP_41') & (clean_data_DL[\"Assignment group\"] != 'GRP_28') & (clean_data_DL[\"Assignment group\"] != 'GRP_40') & (clean_data_DL[\"Assignment group\"] != 'GRP_26') & (clean_data_DL[\"Assignment group\"] != 'GRP_34') & (clean_data_DL[\"Assignment group\"] != 'GRP_6') & (clean_data_DL[\"Assignment group\"] != 'GRP_7') & (clean_data_DL[\"Assignment group\"] != 'GRP_31') & (clean_data_DL[\"Assignment group\"] != 'GRP_9') & (clean_data_DL[\"Assignment group\"] != 'GRP_10')]\n",
    "temp_dataframe4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pDAkIgcubRrJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "clean_data_resampled2 = temp_dataframe3[0:0]\n",
    "for grp in temp_dataframe3['Assignment group'].unique():\n",
    "    temp_dataframe5 = temp_dataframe3.apply(lambda x : True\n",
    "            if str(temp_dataframe3['Assignment group']) == grp else False, axis = 1)\n",
    "    num_rows2 = len(temp_dataframe5[temp_dataframe5 == True].index) \n",
    "    if(num_rows2 < 500):\n",
    "            temp_dataframeGrpDF1 = temp_dataframe3[temp_dataframe3['Assignment group'] == grp]\n",
    "            resampled2 = resample(temp_dataframeGrpDF1, replace=True, n_samples=500, random_state=123)\n",
    "            clean_data_resampled2 = clean_data_resampled2.append(resampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "t2-AI57dbRrJ",
    "outputId": "44f4fa61-150c-4184-ffd9-6ce6fe0ea7de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>language</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>spxqmiry zpwgoqju</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>en</td>\n",
       "      <td>HostName_: volume: / dev / ora_data encourages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>jyoqwxhz clhxsoqy</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>en</td>\n",
       "      <td>HostName_: volume: /dev/SID_ora on server: Hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>pvlxjizg xzvlwqjc</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>en</td>\n",
       "      <td>hostname _ and hostname _ in listener is not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>kbnfxpsy gehxzayq</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>en</td>\n",
       "      <td>considering ticket_no which corresponded fixed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>mnlazfsr mtqrkhnx</td>\n",
       "      <td>GRP_1</td>\n",
       "      <td>en</td>\n",
       "      <td>'s shop_floor_app is intelligence: inaccessibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>hugcadrn ixhlwdgt</td>\n",
       "      <td>GRP_2</td>\n",
       "      <td>en</td>\n",
       "      <td>please remove user hugcadrn ixhlwdgt (ralfteim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>pvbomqht smfkuhwi</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>en</td>\n",
       "      <td>pc received multiple windows security updates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>mpihysnw wrctgoan</td>\n",
       "      <td>GRP_29</td>\n",
       "      <td>en</td>\n",
       "      <td>please contact ed pasgryowski (pasgryo) about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>cpmaidhj elbaqmtp</td>\n",
       "      <td>GRP_3</td>\n",
       "      <td>en</td>\n",
       "      <td>tablet needs reimaged due to multiple issues w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>avglmrts vhqmtiua</td>\n",
       "      <td>GRP_29</td>\n",
       "      <td>en</td>\n",
       "      <td>good afternoon, am not receiving the emails th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Caller  ...                                         Final_Text\n",
       "3574  spxqmiry zpwgoqju  ...  HostName_: volume: / dev / ora_data encourages...\n",
       "1590  jyoqwxhz clhxsoqy  ...  HostName_: volume: /dev/SID_ora on server: Hos...\n",
       "4783  pvlxjizg xzvlwqjc  ...  hostname _ and hostname _ in listener is not a...\n",
       "541   kbnfxpsy gehxzayq  ...  considering ticket_no which corresponded fixed...\n",
       "4454  mnlazfsr mtqrkhnx  ...  's shop_floor_app is intelligence: inaccessibl...\n",
       "...                 ...  ...                                                ...\n",
       "8183  hugcadrn ixhlwdgt  ...  please remove user hugcadrn ixhlwdgt (ralfteim...\n",
       "8186  pvbomqht smfkuhwi  ...  pc received multiple windows security updates ...\n",
       "8189  mpihysnw wrctgoan  ...  please contact ed pasgryowski (pasgryo) about ...\n",
       "8193  cpmaidhj elbaqmtp  ...  tablet needs reimaged due to multiple issues w...\n",
       "8194  avglmrts vhqmtiua  ...  good afternoon, am not receiving the emails th...\n",
       "\n",
       "[41252 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes=[clean_data_resampled2, temp_dataframe4]\n",
    "clean_data_DL = pd.concat(dataframes)\n",
    "clean_data_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bX4pcTxbBhDE"
   },
   "outputs": [],
   "source": [
    "clean_data_DL.to_csv('Interim_data_resampled.csv', index=False, encoding='utf_8_sig')\n",
    "#with open('/content/Final_data.pkl','wb') as f:\n",
    "with open('/content/drive/MyDrive/Capstone/Interim_data_resampled.pkl','wb') as f:\n",
    "    pickle.dump(clean_data_DL, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the augmented data from pickle file \n",
    "with open('/content/drive/MyDrive/Capstone/Interim_data_resampled.pkl','rb') as f:\n",
    "#with open('Interim_data.pkl','rb') as f:\n",
    "    clean_data_DL = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15XBDLMRQWrL",
    "outputId": "052d175e-6fa6-420e-eefc-f408b4b735be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caller              0\n",
       "Assignment group    0\n",
       "language            0\n",
       "Final_Text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_DL.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FxgUQxvhQWrL"
   },
   "outputs": [],
   "source": [
    "clean_data_DL['Final_Text'] = clean_data_DL['Final_Text'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzJ4VnECQWrM",
    "outputId": "6c8f4b48-6480-4107-af8d-478c96ae6bbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41252 entries, 3574 to 8194\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Caller            41252 non-null  object\n",
      " 1   Assignment group  41252 non-null  object\n",
      " 2   language          41252 non-null  object\n",
      " 3   Final_Text        41252 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_data_DL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTiSKPsIr7RX",
    "outputId": "a4cdc8b0-eb26-47f8-9c73-624461d76786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 42, 52, 48,  3,  7,  9, 13, 14, 15, 16, 19, 20, 21, 54, 24, 25,\n",
       "        2, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44,\n",
       "       45, 46, 47, 49, 50, 51, 23, 31, 55, 53,  4,  6,  8, 10, 11, 12, 17,\n",
       "        5, 22, 18, 26,  0])"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "clean_data_DL['Assignment group LabelEncoded']= label_encoder.fit_transform(clean_data_DL['Assignment group']) \n",
    "\n",
    "target_strings = label_encoder.inverse_transform(clean_data_DL['Assignment group LabelEncoded'])\n",
    "target_strings_list = np.unique(target_strings).tolist()\n",
    "\n",
    "clean_data_DL['Assignment group LabelEncoded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwiIGk4ar7gA",
    "outputId": "07c0bf11-1bf3-42e0-eb9e-e6801b99c388"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoded_dict = dict(zip(clean_data_DL['Assignment group'].unique(), clean_data_DL['Assignment group LabelEncoded'].unique()))\n",
    "len(label_encoded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibiTTlGLQWrM",
    "outputId": "f756f021-5508-4255-9014-7f700ec7225b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of the training set:\u001b[0m (28876,) (12376,)\n",
      "\u001b[1mShape of the test set:\u001b[0m (28876,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_data_DL['Final_Text'], clean_data_DL['Assignment group LabelEncoded'], test_size=0.3, random_state = 0, stratify=clean_data_DL['Assignment group LabelEncoded'])\n",
    "print('\\033[1mShape of the training set:\\033[0m', X_train.shape, X_test.shape)\n",
    "print('\\033[1mShape of the test set:\\033[0m', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GOVYYV9QWrM"
   },
   "source": [
    "### Create checkpoints function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RG6wVQXQWrN",
    "outputId": "048405b8-7d46-406c-e652-9a71a5bf1149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Weights’: File exists\n"
     ]
    }
   ],
   "source": [
    "#Path where you want to save the weights, model and checkpoints\n",
    "model_path = \"Weights/\"\n",
    "%mkdir Weights\n",
    "\n",
    "# Define model callbacks\n",
    "def call_backs(name):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.01, patience=3)\n",
    "    model_checkpoint =  ModelCheckpoint(model_path + name + '_epoch{epoch:02d}_loss{val_loss:.4f}.h5',\n",
    "                                                               monitor='val_loss',\n",
    "                                                               verbose=1,\n",
    "                                                               save_best_only=True,\n",
    "                                                               save_weights_only=False,\n",
    "                                                               mode='min',\n",
    "                                                               period=1)\n",
    "    return [model_checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lAC5r5UcQWrN"
   },
   "outputs": [],
   "source": [
    "# Function to build Neural Network\n",
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.3):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpSSx0X4XXHq",
    "outputId": "e5f427e8-ee2f-4b63-b58f-d6d9b1e02d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1280512   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 56)                28728     \n",
      "=================================================================\n",
      "Total params: 2,368,056\n",
      "Trainable params: 2,363,960\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=2500)\n",
    "Tfidf_vect.fit(clean_data_DL.Final_Text.astype(str))\n",
    "X_train_tfidf = Tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = Tfidf_vect.transform(X_test)\n",
    "\n",
    "# Instantiate the network\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a6aC4UqOQWrN",
    "outputId": "c3089176-ae61-405e-89ac-7296cb09511a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28876 samples, validate on 12376 samples\n",
      "Epoch 1/25\n",
      "28876/28876 [==============================] - 5s 169us/step - loss: 2.5223 - accuracy: 0.3905 - val_loss: 3.8746 - val_accuracy: 0.1097\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.87463, saving model to Weights/DNN_epoch01_loss3.8746.h5\n",
      "Epoch 2/25\n",
      "28876/28876 [==============================] - 3s 91us/step - loss: 0.9240 - accuracy: 0.7376 - val_loss: 1.3673 - val_accuracy: 0.6116\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.87463 to 1.36734, saving model to Weights/DNN_epoch02_loss1.3673.h5\n",
      "Epoch 3/25\n",
      "28876/28876 [==============================] - 3s 92us/step - loss: 0.4619 - accuracy: 0.8665 - val_loss: 0.3718 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36734 to 0.37175, saving model to Weights/DNN_epoch03_loss0.3718.h5\n",
      "Epoch 4/25\n",
      "28876/28876 [==============================] - 3s 94us/step - loss: 0.2826 - accuracy: 0.9172 - val_loss: 0.3012 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37175 to 0.30117, saving model to Weights/DNN_epoch04_loss0.3012.h5\n",
      "Epoch 5/25\n",
      "28876/28876 [==============================] - 3s 93us/step - loss: 0.2019 - accuracy: 0.9423 - val_loss: 0.3106 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30117\n",
      "Epoch 6/25\n",
      "28876/28876 [==============================] - 3s 94us/step - loss: 0.1516 - accuracy: 0.9547 - val_loss: 0.3102 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30117\n",
      "Epoch 7/25\n",
      "28876/28876 [==============================] - 3s 93us/step - loss: 0.1290 - accuracy: 0.9623 - val_loss: 0.2891 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30117 to 0.28912, saving model to Weights/DNN_epoch07_loss0.2891.h5\n",
      "Epoch 8/25\n",
      "28876/28876 [==============================] - 3s 94us/step - loss: 0.1146 - accuracy: 0.9667 - val_loss: 0.2954 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28912\n",
      "Epoch 9/25\n",
      "28876/28876 [==============================] - 3s 92us/step - loss: 0.0974 - accuracy: 0.9716 - val_loss: 0.3070 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28912\n",
      "Epoch 10/25\n",
      "28876/28876 [==============================] - 3s 92us/step - loss: 0.0957 - accuracy: 0.9723 - val_loss: 0.2998 - val_accuracy: 0.9351\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28912\n",
      "Estimator: <keras.engine.sequential.Sequential object at 0x7f2c2e909400>\n",
      "================================================================================\n",
      "Training accuracy: 99.30%\n",
      "Testing accuracy: 93.51%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[ 703    0    2 ...    2    2    0]\n",
      " [   0  148    0 ...    0    0    0]\n",
      " [   9    0  135 ...    0    0    0]\n",
      " ...\n",
      " [   0    2    0 ...  420    3    6]\n",
      " [   1    0    0 ...    3  143    1]\n",
      " [   0    0    0 ...    4    2 1418]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             GRP_0       0.87      0.73      0.80       957\n",
      "             GRP_1       0.95      0.99      0.97       150\n",
      "            GRP_10       0.92      0.90      0.91       150\n",
      "            GRP_11       0.99      0.99      0.99       150\n",
      "            GRP_12       0.90      0.88      0.89       426\n",
      "            GRP_13       0.95      0.96      0.95       254\n",
      "            GRP_14       0.82      0.89      0.85       206\n",
      "            GRP_15       0.97      0.99      0.98       150\n",
      "            GRP_16       0.89      0.92      0.90       153\n",
      "            GRP_17       0.94      0.99      0.97       150\n",
      "            GRP_18       0.94      0.91      0.92       153\n",
      "            GRP_19       0.88      0.87      0.88       384\n",
      "             GRP_2       0.84      0.85      0.85       357\n",
      "            GRP_20       0.96      1.00      0.98       150\n",
      "            GRP_21       1.00      1.00      1.00       150\n",
      "            GRP_22       0.96      0.97      0.97       150\n",
      "            GRP_23       0.98      0.99      0.99       150\n",
      "            GRP_24       0.91      0.92      0.92       504\n",
      "            GRP_25       0.87      0.95      0.90       201\n",
      "            GRP_26       0.88      0.97      0.92       150\n",
      "            GRP_27       0.98      1.00      0.99       150\n",
      "            GRP_28       0.92      0.96      0.94       150\n",
      "            GRP_29       0.93      0.88      0.91       170\n",
      "             GRP_3       0.85      0.87      0.86       359\n",
      "            GRP_30       0.97      0.97      0.97       150\n",
      "            GRP_31       0.93      0.95      0.94       150\n",
      "            GRP_33       0.91      0.82      0.86       192\n",
      "            GRP_34       0.89      0.91      0.90       150\n",
      "            GRP_36       0.93      1.00      0.96       150\n",
      "            GRP_37       0.99      0.99      0.99       150\n",
      "            GRP_39       0.90      1.00      0.95       150\n",
      "             GRP_4       0.86      0.83      0.84       178\n",
      "            GRP_40       0.98      0.94      0.96       150\n",
      "            GRP_41       0.99      1.00      1.00       150\n",
      "            GRP_42       0.93      0.95      0.94       150\n",
      "            GRP_43       1.00      1.00      1.00       150\n",
      "            GRP_44       1.00      1.00      1.00       150\n",
      "            GRP_45       0.98      1.00      0.99       150\n",
      "            GRP_46       1.00      1.00      1.00       150\n",
      "            GRP_47       0.98      1.00      0.99       150\n",
      "            GRP_48       0.99      0.99      0.99       150\n",
      "            GRP_49       0.99      1.00      1.00       150\n",
      "             GRP_5       0.99      0.99      0.99       150\n",
      "            GRP_50       0.99      0.97      0.98       150\n",
      "            GRP_51       1.00      1.00      1.00       150\n",
      "            GRP_52       1.00      1.00      1.00       150\n",
      "            GRP_53       0.96      1.00      0.98       150\n",
      "            GRP_59       1.00      1.00      1.00       150\n",
      "             GRP_6       0.93      0.95      0.94       150\n",
      "            GRP_60       0.96      1.00      0.98       150\n",
      "            GRP_62       0.98      0.99      0.98       150\n",
      "            GRP_65       0.99      1.00      1.00       150\n",
      "             GRP_7       0.90      0.98      0.94       150\n",
      "             GRP_8       0.90      0.92      0.91       455\n",
      "             GRP_9       0.92      0.95      0.94       150\n",
      "GRP_MonitoringTool       0.99      0.99      0.99      1427\n",
      "\n",
      "          accuracy                           0.94     12376\n",
      "         macro avg       0.94      0.95      0.95     12376\n",
      "      weighted avg       0.93      0.94      0.93     12376\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'model_DNN.fit(X_train_tfidf, y_train,\\n                              validation_data=(X_test_tfidf, y_test),\\n                              callbacks=call_backs(\"NN\"),\\n                              epochs=10,\\n                              batch_size=128,\\n                              verbose=2)\\npredicted = model_DNN.predict(X_test_tfidf)'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classification(model_DNN, X_train_tfidf, X_test_tfidf, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='DNN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaCQnFBRQWrO"
   },
   "source": [
    "### Extract Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMA3MFYUQWrO",
    "outputId": "1754fbd0-c2de-4877-876d-f4b9431f297c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.6B.300d.txt',\n",
       " 'glove.6B.200d.txt',\n",
       " 'glove.6B.50d.txt',\n",
       " 'glove.6B.100d.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the glove embedding zip file from http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
    "from zipfile import ZipFile\n",
    "# Check if it is already extracted else Open the zipped file as readonly\n",
    "if not os.path.isfile('glove.6B/glove.6B.200d.txt'):\n",
    "    #glove_embeddings = 'glove.6B.zip'\n",
    "    glove_embeddings = '/content/drive/MyDrive/Capstone/glove.6B.zip'\n",
    "    with ZipFile(glove_embeddings, 'r') as archive:\n",
    "        archive.extractall('glove.6B')\n",
    "\n",
    "# List the files under extracted folder\n",
    "os.listdir('glove.6B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2Xtecr3QWrO"
   },
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ghIAygEfQWrO"
   },
   "outputs": [],
   "source": [
    "#gloveFileName = 'glove.6B/glove.6B.200d.txt'\n",
    "gloveFileName = '/content/glove.6B/glove.6B.200d.txt'\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "EMBEDDING_DIM=200\n",
    "MAX_NB_WORDS=75000\n",
    "\n",
    "# Function to generate Embedding\n",
    "def loadData_Tokenizer(X_train, X_test,filename):\n",
    "    np.random.seed(7)\n",
    "    text = np.concatenate((X_train, X_test), axis=0)\n",
    "    text = np.array(text)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_train = text[0:len(X_train), ]\n",
    "    X_test = text[len(X_train):, ]\n",
    "    embeddings_index = {}\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_train, X_test, word_index,embeddings_index)\n",
    "\n",
    "\n",
    "embedding_matrix = []\n",
    "\n",
    "def buildEmbed_matrices(word_index,embedding_dim):\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
    "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])), \"into shape\",str(len(embedding_vector)),\n",
    "                      \" Please make sure your\"\" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
    "                exit(1)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DljFFfKxQWrO",
    "outputId": "a2d84dc1-1d1f-450c-c44b-ae39d96a53b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44936 unique tokens.\n",
      "(41252, 500)\n",
      "Total 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Generate Glove embedded datasets\n",
    "X_train_Glove, X_test_Glove, word_index, embeddings_index = loadData_Tokenizer(X_train,X_test,gloveFileName)\n",
    "embedding_matrix = buildEmbed_matrices(word_index,EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "j1Jz0dfgcZyl"
   },
   "outputs": [],
   "source": [
    "def Build_Model_LSTM_Text(word_index, embeddings_matrix, nclasses,dropout=0.3):\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    lstm = Bidirectional(LSTM(128))(embedded_sequences)\n",
    "    drop = Dropout(0.3)(lstm)\n",
    "    dense = Dense(100,activation='relu')(drop)\n",
    "    preds = Dense(nclasses, activation='softmax')(dense)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOvf1ZbOf_Oc",
    "outputId": "9a4dda21-f4e3-4af3-eb97-ecec1ce48ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 500, 200)          8987400   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               336896    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 56)                5656      \n",
      "=================================================================\n",
      "Total params: 9,355,652\n",
      "Trainable params: 9,355,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 28876 samples, validate on 12376 samples\n",
      "Epoch 1/25\n",
      " 4224/28876 [===>..........................] - ETA: 5:30 - loss: 3.5884 - acc: 0.1813"
     ]
    }
   ],
   "source": [
    "model_CNN_LSTM = Build_Model_LSTM_Text(word_index,embedding_matrix, 56)\n",
    "run_classification(model_CNN_LSTM, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='CNN_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "URiIMsVEQWrO"
   },
   "outputs": [],
   "source": [
    "def Build_Model_CNN_Text(word_index, embeddings_matrix, nclasses,dropout=0.3):\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "    # applying a more complex convolutional approach\n",
    "    convs = []\n",
    "    filter_sizes = []\n",
    "    layer = 5\n",
    "    print(\"Filter  \",layer)\n",
    "    for fl in range(0,layer):\n",
    "        filter_sizes.append((fl+2))\n",
    "    node = 128\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(node, kernel_size=fsz, activation='relu')(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(5)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "    l_cov1 = Conv1D(node, 5, activation='relu')(l_merge)\n",
    "    l_cov1 = Dropout(dropout)(l_cov1)\n",
    "    l_batch1 = BatchNormalization()(l_cov1)\n",
    "    l_pool1 = MaxPooling1D(5)(l_batch1)\n",
    "    l_cov2 = Conv1D(node, 5, activation='relu')(l_pool1)\n",
    "    l_cov2 = Dropout(dropout)(l_cov2)\n",
    "    l_batch2 = BatchNormalization()(l_cov2)\n",
    "    l_pool2 = MaxPooling1D(30)(l_batch2)\n",
    "    l_flat = Flatten()(l_pool2)\n",
    "    l_dense = Dense(1024, activation='relu')(l_flat)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "    l_dense = Dense(512, activation='relu')(l_dense)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxdeJLw9QWrP",
    "outputId": "0abc80b6-da2d-448b-f096-8ca1c0d8a18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter   5\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 500, 200)     8987400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 499, 128)     51328       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 498, 128)     76928       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 497, 128)     102528      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 496, 128)     128128      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 495, 128)     153728      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 99, 128)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 99, 128)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 99, 128)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 99, 128)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 99, 128)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 495, 128)     0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 491, 128)     82048       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 491, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 491, 128)     512         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 98, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 94, 128)      82048       max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 94, 128)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 94, 128)      512         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 3, 128)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 384)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         394240      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          524800      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 56)           28728       dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,612,928\n",
      "Trainable params: 10,612,416\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 28876 samples, validate on 12376 samples\n",
      "Epoch 1/25\n",
      "28876/28876 [==============================] - 34s 1ms/step - loss: 3.7319 - accuracy: 0.1342 - val_loss: 3.6387 - val_accuracy: 0.2122\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.63869, saving model to Weights/CNN_epoch01_loss3.6387.h5\n",
      "Epoch 2/25\n",
      "28876/28876 [==============================] - 26s 912us/step - loss: 3.2144 - accuracy: 0.2167 - val_loss: 3.2941 - val_accuracy: 0.1839\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.63869 to 3.29412, saving model to Weights/CNN_epoch02_loss3.2941.h5\n",
      "Epoch 3/25\n",
      "28876/28876 [==============================] - 27s 918us/step - loss: 2.8881 - accuracy: 0.2462 - val_loss: 3.1702 - val_accuracy: 0.2123\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.29412 to 3.17024, saving model to Weights/CNN_epoch03_loss3.1702.h5\n",
      "Epoch 4/25\n",
      "28876/28876 [==============================] - 26s 915us/step - loss: 2.5770 - accuracy: 0.2845 - val_loss: 2.6752 - val_accuracy: 0.3123\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.17024 to 2.67523, saving model to Weights/CNN_epoch04_loss2.6752.h5\n",
      "Epoch 5/25\n",
      "28876/28876 [==============================] - 26s 915us/step - loss: 2.2125 - accuracy: 0.3438 - val_loss: 2.2126 - val_accuracy: 0.3708\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.67523 to 2.21263, saving model to Weights/CNN_epoch05_loss2.2126.h5\n",
      "Epoch 6/25\n",
      "28876/28876 [==============================] - 26s 912us/step - loss: 1.8079 - accuracy: 0.4302 - val_loss: 1.9153 - val_accuracy: 0.4136\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.21263 to 1.91527, saving model to Weights/CNN_epoch06_loss1.9153.h5\n",
      "Epoch 7/25\n",
      "28876/28876 [==============================] - 26s 908us/step - loss: 1.4401 - accuracy: 0.5281 - val_loss: 1.5208 - val_accuracy: 0.5534\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.91527 to 1.52080, saving model to Weights/CNN_epoch07_loss1.5208.h5\n",
      "Epoch 8/25\n",
      "28876/28876 [==============================] - 26s 908us/step - loss: 1.1150 - accuracy: 0.6285 - val_loss: 1.2920 - val_accuracy: 0.6252\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.52080 to 1.29203, saving model to Weights/CNN_epoch08_loss1.2920.h5\n",
      "Epoch 9/25\n",
      "28876/28876 [==============================] - 26s 908us/step - loss: 0.8771 - accuracy: 0.7101 - val_loss: 1.0384 - val_accuracy: 0.7128\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.29203 to 1.03836, saving model to Weights/CNN_epoch09_loss1.0384.h5\n",
      "Epoch 10/25\n",
      "28876/28876 [==============================] - 26s 906us/step - loss: 0.6888 - accuracy: 0.7715 - val_loss: 0.9697 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.03836 to 0.96966, saving model to Weights/CNN_epoch10_loss0.9697.h5\n",
      "Epoch 11/25\n",
      "28876/28876 [==============================] - 26s 909us/step - loss: 0.5274 - accuracy: 0.8316 - val_loss: 0.8354 - val_accuracy: 0.7608\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.96966 to 0.83535, saving model to Weights/CNN_epoch11_loss0.8354.h5\n",
      "Epoch 12/25\n",
      "28876/28876 [==============================] - 26s 910us/step - loss: 0.3940 - accuracy: 0.8751 - val_loss: 0.7964 - val_accuracy: 0.7724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.83535 to 0.79642, saving model to Weights/CNN_epoch12_loss0.7964.h5\n",
      "Epoch 13/25\n",
      "28876/28876 [==============================] - 26s 906us/step - loss: 0.3180 - accuracy: 0.9007 - val_loss: 0.7578 - val_accuracy: 0.7758\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.79642 to 0.75776, saving model to Weights/CNN_epoch13_loss0.7578.h5\n",
      "Epoch 14/25\n",
      "28876/28876 [==============================] - 26s 908us/step - loss: 0.2621 - accuracy: 0.9201 - val_loss: 0.6374 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.75776 to 0.63736, saving model to Weights/CNN_epoch14_loss0.6374.h5\n",
      "Epoch 15/25\n",
      "28876/28876 [==============================] - 26s 906us/step - loss: 0.2127 - accuracy: 0.9351 - val_loss: 0.6567 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.63736\n",
      "Epoch 16/25\n",
      "28876/28876 [==============================] - 26s 908us/step - loss: 0.1899 - accuracy: 0.9434 - val_loss: 0.6772 - val_accuracy: 0.8112\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63736\n",
      "Epoch 17/25\n",
      "28876/28876 [==============================] - 26s 905us/step - loss: 0.1663 - accuracy: 0.9499 - val_loss: 0.6807 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.63736\n",
      "Estimator: <keras.engine.training.Model object at 0x7f2ba9134ef0>\n",
      "================================================================================\n",
      "Training accuracy: 91.89%\n",
      "Testing accuracy: 81.47%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[ 521    1   11 ...    1    2    0]\n",
      " [   0  150    0 ...    0    0    0]\n",
      " [   0    0  105 ...    0    0    0]\n",
      " ...\n",
      " [   0    2    0 ...  397    0    0]\n",
      " [   6    0   10 ...    1   36    0]\n",
      " [   0    0    0 ...    0    0 1427]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             GRP_0       0.78      0.54      0.64       957\n",
      "             GRP_1       0.84      1.00      0.91       150\n",
      "            GRP_10       0.66      0.70      0.68       150\n",
      "            GRP_11       0.70      0.98      0.82       150\n",
      "            GRP_12       0.94      0.67      0.78       426\n",
      "            GRP_13       0.86      0.72      0.79       254\n",
      "            GRP_14       0.64      0.69      0.66       206\n",
      "            GRP_15       0.79      0.99      0.88       150\n",
      "            GRP_16       0.87      0.47      0.61       153\n",
      "            GRP_17       0.55      1.00      0.71       150\n",
      "            GRP_18       0.82      0.74      0.78       153\n",
      "            GRP_19       0.77      0.50      0.61       384\n",
      "             GRP_2       0.88      0.45      0.60       357\n",
      "            GRP_20       0.96      0.97      0.97       150\n",
      "            GRP_21       0.60      0.98      0.75       150\n",
      "            GRP_22       0.85      0.95      0.89       150\n",
      "            GRP_23       0.97      0.98      0.97       150\n",
      "            GRP_24       0.92      0.90      0.91       504\n",
      "            GRP_25       0.87      0.71      0.78       201\n",
      "            GRP_26       0.79      0.85      0.82       150\n",
      "            GRP_27       0.62      0.93      0.75       150\n",
      "            GRP_28       0.68      0.75      0.71       150\n",
      "            GRP_29       0.59      0.79      0.68       170\n",
      "             GRP_3       0.68      0.53      0.59       359\n",
      "            GRP_30       0.64      0.95      0.76       150\n",
      "            GRP_31       0.47      0.75      0.58       150\n",
      "            GRP_33       0.55      0.42      0.48       192\n",
      "            GRP_34       0.59      0.60      0.60       150\n",
      "            GRP_36       0.76      0.93      0.83       150\n",
      "            GRP_37       0.86      0.86      0.86       150\n",
      "            GRP_39       0.90      1.00      0.95       150\n",
      "             GRP_4       0.91      0.65      0.76       178\n",
      "            GRP_40       0.97      0.81      0.88       150\n",
      "            GRP_41       0.61      0.97      0.75       150\n",
      "            GRP_42       0.52      0.98      0.68       150\n",
      "            GRP_43       0.99      1.00      1.00       150\n",
      "            GRP_44       0.93      1.00      0.96       150\n",
      "            GRP_45       0.82      0.97      0.89       150\n",
      "            GRP_46       0.90      1.00      0.95       150\n",
      "            GRP_47       0.82      1.00      0.90       150\n",
      "            GRP_48       0.80      0.94      0.87       150\n",
      "            GRP_49       0.97      1.00      0.99       150\n",
      "             GRP_5       0.91      0.83      0.87       150\n",
      "            GRP_50       0.99      0.99      0.99       150\n",
      "            GRP_51       0.99      1.00      1.00       150\n",
      "            GRP_52       0.99      1.00      0.99       150\n",
      "            GRP_53       0.80      1.00      0.89       150\n",
      "            GRP_59       0.95      1.00      0.97       150\n",
      "             GRP_6       0.90      0.84      0.87       150\n",
      "            GRP_60       0.84      1.00      0.91       150\n",
      "            GRP_62       0.79      0.78      0.78       150\n",
      "            GRP_65       0.98      0.98      0.98       150\n",
      "             GRP_7       0.65      0.99      0.78       150\n",
      "             GRP_8       0.93      0.87      0.90       455\n",
      "             GRP_9       0.95      0.24      0.38       150\n",
      "GRP_MonitoringTool       1.00      1.00      1.00      1427\n",
      "\n",
      "          accuracy                           0.81     12376\n",
      "         macro avg       0.81      0.84      0.81     12376\n",
      "      weighted avg       0.83      0.81      0.81     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the network and run classification\n",
    "model_CNN = Build_Model_CNN_Text(word_index,embedding_matrix, 56)\n",
    "run_classification(model_CNN, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMu2ONzLQWrP"
   },
   "source": [
    "## Recurrent Neural Networks (RNN) --> Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "grFaHdizQWrP"
   },
   "outputs": [],
   "source": [
    "def Build_Model_RNN_Text(word_index, embeddings_matrix, nclasses,dropout=0.5):\n",
    "    model = Sequential()\n",
    "    hidden_layer = 3\n",
    "    gru_node = 128\n",
    "    model.add(Input(shape=(MAX_SEQUENCE_LENGTH,),dtype='int64'))\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True))\n",
    "    #print(gru_node)\n",
    "    '''for i in range(0,hidden_layer):\n",
    "        model.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())'''\n",
    "    model.add(GRU(gru_node))\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(nclasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GlNeKO-3QWrP",
    "outputId": "ce50c770-6109-4da9-8be2-62ff1f87ea07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 200)          8987400   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               126336    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 56)                5656      \n",
      "=================================================================\n",
      "Total params: 9,132,292\n",
      "Trainable params: 9,132,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 28876 samples, validate on 12376 samples\n",
      "Epoch 1/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 2.5796 - acc: 0.3651\n",
      "Epoch 00001: val_loss improved from inf to 1.45658, saving model to Weights/RNN_epoch01_loss1.4566.h5\n",
      "28876/28876 [==============================] - 151s 5ms/sample - loss: 2.5765 - acc: 0.3659 - val_loss: 1.4566 - val_acc: 0.6045\n",
      "Epoch 2/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 1.0227 - acc: 0.7143\n",
      "Epoch 00002: val_loss improved from 1.45658 to 0.69656, saving model to Weights/RNN_epoch02_loss0.6966.h5\n",
      "28876/28876 [==============================] - 153s 5ms/sample - loss: 1.0214 - acc: 0.7147 - val_loss: 0.6966 - val_acc: 0.8021\n",
      "Epoch 3/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8705\n",
      "Epoch 00003: val_loss improved from 0.69656 to 0.44992, saving model to Weights/RNN_epoch03_loss0.4499.h5\n",
      "28876/28876 [==============================] - 150s 5ms/sample - loss: 0.4616 - acc: 0.8704 - val_loss: 0.4499 - val_acc: 0.8707\n",
      "Epoch 4/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9359\n",
      "Epoch 00004: val_loss improved from 0.44992 to 0.36084, saving model to Weights/RNN_epoch04_loss0.3608.h5\n",
      "28876/28876 [==============================] - 148s 5ms/sample - loss: 0.2291 - acc: 0.9360 - val_loss: 0.3608 - val_acc: 0.9034\n",
      "Epoch 5/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9654\n",
      "Epoch 00005: val_loss improved from 0.36084 to 0.31245, saving model to Weights/RNN_epoch05_loss0.3125.h5\n",
      "28876/28876 [==============================] - 147s 5ms/sample - loss: 0.1282 - acc: 0.9654 - val_loss: 0.3125 - val_acc: 0.9172\n",
      "Epoch 6/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9800\n",
      "Epoch 00006: val_loss improved from 0.31245 to 0.29905, saving model to Weights/RNN_epoch06_loss0.2991.h5\n",
      "28876/28876 [==============================] - 146s 5ms/sample - loss: 0.0782 - acc: 0.9799 - val_loss: 0.2991 - val_acc: 0.9235\n",
      "Epoch 7/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9871\n",
      "Epoch 00007: val_loss did not improve from 0.29905\n",
      "28876/28876 [==============================] - 148s 5ms/sample - loss: 0.0537 - acc: 0.9871 - val_loss: 0.3023 - val_acc: 0.9257\n",
      "Epoch 8/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9898\n",
      "Epoch 00008: val_loss did not improve from 0.29905\n",
      "28876/28876 [==============================] - 145s 5ms/sample - loss: 0.0401 - acc: 0.9899 - val_loss: 0.3064 - val_acc: 0.9262\n",
      "Epoch 9/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9921\n",
      "Epoch 00009: val_loss did not improve from 0.29905\n",
      "28876/28876 [==============================] - 149s 5ms/sample - loss: 0.0325 - acc: 0.9921 - val_loss: 0.3236 - val_acc: 0.9263\n",
      "Estimator: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3b3ed4b390>\n",
      "================================================================================\n",
      "Training accuracy: 99.58%\n",
      "Testing accuracy: 92.63%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[ 711    0    5 ...    1    2    0]\n",
      " [   0  150    0 ...    0    0    0]\n",
      " [   0    0  144 ...    0    0    0]\n",
      " ...\n",
      " [   0    5    0 ...  424    3    0]\n",
      " [   3    0    0 ...    6  134    0]\n",
      " [   0    0    0 ...    0    0 1427]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             GRP_0       0.82      0.74      0.78       957\n",
      "             GRP_1       0.94      1.00      0.97       150\n",
      "            GRP_10       0.93      0.96      0.94       150\n",
      "            GRP_11       0.97      0.97      0.97       150\n",
      "            GRP_12       0.94      0.88      0.91       426\n",
      "            GRP_13       0.95      0.90      0.93       254\n",
      "            GRP_14       0.72      0.88      0.79       206\n",
      "            GRP_15       0.95      0.98      0.96       150\n",
      "            GRP_16       0.92      0.84      0.88       153\n",
      "            GRP_17       1.00      1.00      1.00       150\n",
      "            GRP_18       0.83      0.93      0.88       153\n",
      "            GRP_19       0.81      0.82      0.81       384\n",
      "             GRP_2       0.75      0.90      0.82       357\n",
      "            GRP_20       0.97      0.97      0.97       150\n",
      "            GRP_21       0.97      0.97      0.97       150\n",
      "            GRP_22       0.95      0.97      0.96       150\n",
      "            GRP_23       0.97      0.99      0.98       150\n",
      "            GRP_24       0.94      0.93      0.93       504\n",
      "            GRP_25       0.93      0.89      0.91       201\n",
      "            GRP_26       0.96      0.96      0.96       150\n",
      "            GRP_27       0.98      0.98      0.98       150\n",
      "            GRP_28       0.89      0.93      0.91       150\n",
      "            GRP_29       0.90      0.88      0.89       170\n",
      "             GRP_3       0.86      0.79      0.82       359\n",
      "            GRP_30       0.91      0.95      0.93       150\n",
      "            GRP_31       0.94      0.86      0.90       150\n",
      "            GRP_33       0.86      0.87      0.86       192\n",
      "            GRP_34       0.95      0.85      0.90       150\n",
      "            GRP_36       0.96      1.00      0.98       150\n",
      "            GRP_37       0.97      0.99      0.98       150\n",
      "            GRP_39       0.96      1.00      0.98       150\n",
      "             GRP_4       0.92      0.79      0.85       178\n",
      "            GRP_40       0.97      0.96      0.97       150\n",
      "            GRP_41       0.93      0.99      0.96       150\n",
      "            GRP_42       0.91      0.93      0.92       150\n",
      "            GRP_43       0.99      1.00      1.00       150\n",
      "            GRP_44       0.97      1.00      0.99       150\n",
      "            GRP_45       0.91      0.99      0.95       150\n",
      "            GRP_46       0.99      1.00      1.00       150\n",
      "            GRP_47       0.97      1.00      0.99       150\n",
      "            GRP_48       0.97      0.98      0.98       150\n",
      "            GRP_49       1.00      1.00      1.00       150\n",
      "             GRP_5       0.97      0.97      0.97       150\n",
      "            GRP_50       0.95      1.00      0.97       150\n",
      "            GRP_51       1.00      1.00      1.00       150\n",
      "            GRP_52       1.00      1.00      1.00       150\n",
      "            GRP_53       0.98      1.00      0.99       150\n",
      "            GRP_59       1.00      1.00      1.00       150\n",
      "             GRP_6       0.93      0.91      0.92       150\n",
      "            GRP_60       1.00      1.00      1.00       150\n",
      "            GRP_62       0.99      0.92      0.95       150\n",
      "            GRP_65       0.99      1.00      0.99       150\n",
      "             GRP_7       0.95      0.94      0.94       150\n",
      "             GRP_8       0.91      0.93      0.92       455\n",
      "             GRP_9       0.89      0.89      0.89       150\n",
      "GRP_MonitoringTool       1.00      1.00      1.00      1427\n",
      "\n",
      "          accuracy                           0.93     12376\n",
      "         macro avg       0.94      0.94      0.94     12376\n",
      "      weighted avg       0.93      0.93      0.93     12376\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the network and run classification\n",
    "model_RNN = Build_Model_RNN_Text(word_index,embedding_matrix, 56)\n",
    "run_classification(model_RNN, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='RNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVAZo1u8QWrP"
   },
   "source": [
    "## RNN with Bidirectional LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "gtFjAJ4oQWrQ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "#gloveFileName = 'glove.6B/glove.6B.100d.txt'\n",
    "gloveFileName = '/content/glove.6B/glove.6B.200d.txt'\n",
    "\n",
    "def Build_Model_LTSM_Text(word_index, embeddings_matrix, nclasses):\n",
    "    kernel_size = 10\n",
    "    filters = 100\n",
    "    pool_size = 2\n",
    "    gru_node = 128\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(MAX_SEQUENCE_LENGTH,),dtype='int64'))\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embeddings_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    #model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    #model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Bidirectional(LSTM(gru_node)))\n",
    "    #model.add(Bidirectional(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    #model.add(Bidirectional(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2)))\n",
    "    #model.add(Bidirectional(LSTM(gru_node, recurrent_dropout=0.2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(nclasses,activation='softmax'))\n",
    "    #model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u0973kvsQWrQ",
    "outputId": "e3554964-6d6f-4cd1-eee9-18817e539275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44936 unique tokens.\n",
      "(41252, 500)\n",
      "Total 400001 word vectors.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 200)          8987400   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 491, 100)          200100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 245, 100)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 245, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 236, 100)          100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 118, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 56)                5656      \n",
      "=================================================================\n",
      "Total params: 9,553,452\n",
      "Trainable params: 9,553,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 28876 samples, validate on 12376 samples\n",
      "Epoch 1/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 3.0725 - acc: 0.2474\n",
      "Epoch 00001: val_loss improved from inf to 2.28253, saving model to Weights/LSTM_epoch01_loss2.2825.h5\n",
      "28876/28876 [==============================] - 99s 3ms/sample - loss: 3.0717 - acc: 0.2475 - val_loss: 2.2825 - val_acc: 0.3963\n",
      "Epoch 2/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 1.8524 - acc: 0.4787\n",
      "Epoch 00002: val_loss improved from 2.28253 to 1.40407, saving model to Weights/LSTM_epoch02_loss1.4041.h5\n",
      "28876/28876 [==============================] - 90s 3ms/sample - loss: 1.8516 - acc: 0.4789 - val_loss: 1.4041 - val_acc: 0.5814\n",
      "Epoch 3/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 1.0685 - acc: 0.6768\n",
      "Epoch 00003: val_loss improved from 1.40407 to 0.88023, saving model to Weights/LSTM_epoch03_loss0.8802.h5\n",
      "28876/28876 [==============================] - 89s 3ms/sample - loss: 1.0690 - acc: 0.6767 - val_loss: 0.8802 - val_acc: 0.7485\n",
      "Epoch 4/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.6506 - acc: 0.8038\n",
      "Epoch 00004: val_loss improved from 0.88023 to 0.68736, saving model to Weights/LSTM_epoch04_loss0.6874.h5\n",
      "28876/28876 [==============================] - 89s 3ms/sample - loss: 0.6502 - acc: 0.8040 - val_loss: 0.6874 - val_acc: 0.8001\n",
      "Epoch 5/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.4216 - acc: 0.8718\n",
      "Epoch 00005: val_loss improved from 0.68736 to 0.52800, saving model to Weights/LSTM_epoch05_loss0.5280.h5\n",
      "28876/28876 [==============================] - 88s 3ms/sample - loss: 0.4211 - acc: 0.8720 - val_loss: 0.5280 - val_acc: 0.8493\n",
      "Epoch 6/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.2893 - acc: 0.9125\n",
      "Epoch 00006: val_loss improved from 0.52800 to 0.47835, saving model to Weights/LSTM_epoch06_loss0.4783.h5\n",
      "28876/28876 [==============================] - 91s 3ms/sample - loss: 0.2891 - acc: 0.9126 - val_loss: 0.4783 - val_acc: 0.8690\n",
      "Epoch 7/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9413\n",
      "Epoch 00007: val_loss improved from 0.47835 to 0.46341, saving model to Weights/LSTM_epoch07_loss0.4634.h5\n",
      "28876/28876 [==============================] - 87s 3ms/sample - loss: 0.1995 - acc: 0.9412 - val_loss: 0.4634 - val_acc: 0.8795\n",
      "Epoch 8/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9511\n",
      "Epoch 00008: val_loss did not improve from 0.46341\n",
      "28876/28876 [==============================] - 87s 3ms/sample - loss: 0.1600 - acc: 0.9511 - val_loss: 0.4844 - val_acc: 0.8772\n",
      "Epoch 9/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 00009: val_loss improved from 0.46341 to 0.44831, saving model to Weights/LSTM_epoch09_loss0.4483.h5\n",
      "28876/28876 [==============================] - 89s 3ms/sample - loss: 0.1265 - acc: 0.9614 - val_loss: 0.4483 - val_acc: 0.8912\n",
      "Epoch 10/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9645\n",
      "Epoch 00010: val_loss improved from 0.44831 to 0.43892, saving model to Weights/LSTM_epoch10_loss0.4389.h5\n",
      "28876/28876 [==============================] - 87s 3ms/sample - loss: 0.1176 - acc: 0.9646 - val_loss: 0.4389 - val_acc: 0.8969\n",
      "Epoch 11/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9703\n",
      "Epoch 00011: val_loss did not improve from 0.43892\n",
      "28876/28876 [==============================] - 89s 3ms/sample - loss: 0.0969 - acc: 0.9704 - val_loss: 0.4695 - val_acc: 0.8944\n",
      "Epoch 12/25\n",
      "28800/28876 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9729\n",
      "Epoch 00012: val_loss did not improve from 0.43892\n",
      "28876/28876 [==============================] - 87s 3ms/sample - loss: 0.0906 - acc: 0.9730 - val_loss: 0.4645 - val_acc: 0.8975\n",
      "Estimator: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3abeda8cf8>\n",
      "================================================================================\n",
      "Training accuracy: 99.05%\n",
      "Testing accuracy: 89.75%\n",
      "================================================================================\n",
      "Confusion matrix:\n",
      " [[ 690    0    1 ...    1    6    0]\n",
      " [   0  147    0 ...    0    0    0]\n",
      " [   0    0  134 ...    0    0    0]\n",
      " ...\n",
      " [   0    1    0 ...  412    0    0]\n",
      " [   7    0    1 ...    4  122    0]\n",
      " [   1    0    0 ...    0    0 1421]]\n",
      "================================================================================\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             GRP_0       0.81      0.72      0.76       957\n",
      "             GRP_1       0.98      0.98      0.98       150\n",
      "            GRP_10       0.84      0.89      0.86       150\n",
      "            GRP_11       0.91      0.98      0.94       150\n",
      "            GRP_12       0.93      0.79      0.85       426\n",
      "            GRP_13       0.85      0.87      0.86       254\n",
      "            GRP_14       0.78      0.76      0.77       206\n",
      "            GRP_15       0.97      0.94      0.96       150\n",
      "            GRP_16       0.65      0.83      0.73       153\n",
      "            GRP_17       0.96      0.99      0.98       150\n",
      "            GRP_18       0.88      0.75      0.81       153\n",
      "            GRP_19       0.70      0.76      0.73       384\n",
      "             GRP_2       0.76      0.80      0.78       357\n",
      "            GRP_20       0.91      0.98      0.95       150\n",
      "            GRP_21       0.93      0.95      0.94       150\n",
      "            GRP_22       0.99      0.91      0.95       150\n",
      "            GRP_23       0.96      0.96      0.96       150\n",
      "            GRP_24       0.97      0.87      0.92       504\n",
      "            GRP_25       0.80      0.89      0.84       201\n",
      "            GRP_26       0.94      0.89      0.91       150\n",
      "            GRP_27       0.97      0.99      0.98       150\n",
      "            GRP_28       0.77      0.87      0.82       150\n",
      "            GRP_29       0.70      0.81      0.75       170\n",
      "             GRP_3       0.70      0.82      0.76       359\n",
      "            GRP_30       0.99      0.86      0.92       150\n",
      "            GRP_31       0.92      0.80      0.86       150\n",
      "            GRP_33       0.77      0.80      0.78       192\n",
      "            GRP_34       0.80      0.82      0.81       150\n",
      "            GRP_36       0.95      0.99      0.97       150\n",
      "            GRP_37       0.98      1.00      0.99       150\n",
      "            GRP_39       0.97      1.00      0.98       150\n",
      "             GRP_4       0.84      0.77      0.80       178\n",
      "            GRP_40       0.94      0.92      0.93       150\n",
      "            GRP_41       0.92      0.96      0.94       150\n",
      "            GRP_42       0.92      0.91      0.92       150\n",
      "            GRP_43       1.00      1.00      1.00       150\n",
      "            GRP_44       0.99      1.00      1.00       150\n",
      "            GRP_45       0.97      0.99      0.98       150\n",
      "            GRP_46       1.00      1.00      1.00       150\n",
      "            GRP_47       0.98      1.00      0.99       150\n",
      "            GRP_48       0.99      0.97      0.98       150\n",
      "            GRP_49       0.99      1.00      1.00       150\n",
      "             GRP_5       0.97      0.99      0.98       150\n",
      "            GRP_50       1.00      1.00      1.00       150\n",
      "            GRP_51       0.98      1.00      0.99       150\n",
      "            GRP_52       1.00      1.00      1.00       150\n",
      "            GRP_53       0.99      1.00      1.00       150\n",
      "            GRP_59       0.99      1.00      0.99       150\n",
      "             GRP_6       0.91      0.84      0.87       150\n",
      "            GRP_60       0.98      1.00      0.99       150\n",
      "            GRP_62       0.80      0.96      0.87       150\n",
      "            GRP_65       0.96      1.00      0.98       150\n",
      "             GRP_7       0.91      0.91      0.91       150\n",
      "             GRP_8       0.94      0.91      0.92       455\n",
      "             GRP_9       0.81      0.81      0.81       150\n",
      "GRP_MonitoringTool       1.00      1.00      1.00      1427\n",
      "\n",
      "          accuracy                           0.90     12376\n",
      "         macro avg       0.91      0.91      0.91     12376\n",
      "      weighted avg       0.90      0.90      0.90     12376\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test,gloveFileName)\n",
    "embedding_matrix = buildEmbed_matrices(word_index,EMBEDDING_DIM)\n",
    "\n",
    "model_LTSM = Build_Model_LTSM_Text(word_index,embedding_matrix, 56                                                                                                                                                                        )\n",
    "run_classification(model_LTSM, X_train_Glove, X_test_Glove, y_train, y_test,pipelineRequired = False,isDeepModel=True, arch_name='LSTM')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3rdJan2021_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
